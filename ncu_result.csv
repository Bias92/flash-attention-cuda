==PROF== Connected to process 26448 (C:\Users\PC\AppData\Local\Programs\Python\Python311\python.exe)
Compiling CUDA kernel (JIT)...
[1/2] cl /showIncludes -DTORCH_EXTENSION_NAME=flash_attn_ext -DTORCH_API_INCLUDE_EXTENSION_H -IC:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include -IC:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include -IC:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\TH -IC:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\THC "-IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include" -IC:\Users\PC\AppData\Local\Programs\Python\Python311\Include -D_GLIBCXX_USE_CXX11_ABI=0 /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /wd4624 /wd4067 /wd4068 /EHsc /std:c++17 -c C:\Users\PC\Desktop\flash-attention-cuda\_wrapper.cpp /Fo_wrapper.o 
Microsoft (R) C/C++ 최적화 컴파일러 버전 19.42.34436(x64)
Copyright (c) Microsoft Corporation. All rights reserved.

참고: 포함 파일: C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/extension.h
참고: 포함 파일:  C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/all.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/autograd.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/autograd.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/variable.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/python_stub.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/Export.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/macros/Export.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/macros/cmake_macros.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/cpp_hook.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/function_hook.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Tensor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/TensorBody.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/Device.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/DeviceType.h
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cstddef
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\yvals_core.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vcruntime.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\sal.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\concurrencysal.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vadefs.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xkeycheck.h
참고: 포함 파일:              C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\stddef.h
참고: 포함 파일:               C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xtr1common
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cstdint
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\stdint.h
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\functional
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\exception
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\yvals.h
참고: 포함 파일:                C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\crtdbg.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vcruntime_new_debug.h
참고: 포함 파일:                  C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vcruntime_new.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\crtdefs.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\use_ansi.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cstdlib
참고: 포함 파일:                C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\math.h
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_math.h
참고: 포함 파일:                C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\stdlib.h
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_malloc.h
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_search.h
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wstdlib.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\limits.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\type_traits
참고: 포함 파일:               C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\malloc.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vcruntime_exception.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\eh.h
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_terminate.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\tuple
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_iter_core.hpp
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\utility
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\initializer_list
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\typeinfo
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vcruntime_typeinfo.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xmemory
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\limits
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cfloat
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\float.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\climits
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cwchar
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cstdio
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\stdio.h
참고: 포함 파일:                   C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wstdio.h
참고: 포함 파일:                    C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_stdio_config.h
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\wchar.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_memcpy_s.h
참고: 포함 파일:                   C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\errno.h
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vcruntime_string.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wconio.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wctype.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wdirect.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wio.h
참고: 포함 파일:                   C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_share.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wprocess.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wstring.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_wtime.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\sys/stat.h
참고: 포함 파일:                   C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\sys/types.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\intrin0.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\intrin0.inl.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\new
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xatomic.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xutility
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cstring
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\string.h
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_memory.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\unordered_map
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xhash
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cmath
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\list
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xpolymorphic_allocator.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vector
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_bit_utils.hpp
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_sanitizer_annotate_container.hpp
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xbit_ops.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xnode_handle.h
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\ostream
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\ios
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xlocnum
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\iterator
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\iosfwd
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\streambuf
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xiosbase
참고: 포함 파일:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\share.h
참고: 포함 파일:                  C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\system_error
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_system_error_abi.hpp
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cerrno
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\stdexcept
참고: 포함 파일:                    C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xstring
참고: 포함 파일:                     C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_string_view.hpp
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xcall_once.h
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xerrc.h
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\atomic
참고: 포함 파일:                    C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xthreads.h
참고: 포함 파일:                     C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_threads_core.hpp
참고: 포함 파일:                     C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xtimec.h
참고: 포함 파일:                      C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\ctime
참고: 포함 파일:                       C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\time.h
참고: 포함 파일:                  C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xlocale
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\memory
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xfacet
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xlocinfo
참고: 포함 파일:                    C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_xlocinfo_types.hpp
참고: 포함 파일:                    C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cctype
참고: 포함 파일:                     C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\ctype.h
참고: 포함 파일:                    C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\clocale
참고: 포함 파일:                     C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\locale.h
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\string
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Exception.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/macros/Macros.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cassert
참고: 포함 파일:               C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\assert.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/StringUtil.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/string_utils.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/string_view.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\algorithm
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_heap_algorithms.hpp
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_minmax.hpp
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\string_view
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\sstream
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\istream
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\variant
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xsmf_control.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/Layout.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/Backend.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/DispatchKey.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/DispatchKeySet.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Metaprogramming.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/TypeList.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/TypeTraits.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/llvmMathExtras.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/bit_cast.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cassert
참고: 포함 파일:                C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\assert.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\array
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/MemoryFormat.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/ArrayRef.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Deprecated.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/SmallVector.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/AlignOf.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cassert
참고: 포함 파일:               C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\assert.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/QScheme.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/Stream.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/Scalar.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/OptionalRef.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/ScalarType.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/BFloat16.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/BFloat16-inl.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_e4m3fn.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/TypeSafeSignMath.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/floating_point_utils.h
참고: 포함 파일:              C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\math.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\intrin.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\setjmp.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\immintrin.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\wmmintrin.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\nmmintrin.h
참고: 포함 파일:                  C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\smmintrin.h
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\tmmintrin.h
참고: 포함 파일:                    C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\pmmintrin.h
참고: 포함 파일:                     C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\emmintrin.h
참고: 포함 파일:                      C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xmmintrin.h
참고: 포함 파일:                       C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\mmintrin.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\zmmintrin.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\ammintrin.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_e4m3fn-inl.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_e4m3fnuz.h
참고: 포함 파일:              C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\math.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_e4m3fnuz-inl.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_fnuz_cvt.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_e5m2.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Half.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/complex.h
참고: 포함 파일:                C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\complex
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\ymath.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/complex_math.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/complex_utils.h
참고: 포함 파일:               C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\math.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Half-inl.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_e5m2-inl.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_e5m2fnuz.h
참고: 포함 파일:              C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\math.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Float8_e5m2fnuz-inl.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/bits.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/qint32.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/qint8.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/quint2x4.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/quint4x2.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/quint8.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/SymBool.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/SymNodeImpl.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Optional.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\optional
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/intrusive_ptr.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/MaybeOwned.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/SymFloat.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/SymInt.h
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\numeric
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/TypeCast.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/ScalarTypeToTypeMeta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/typeid.h
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\mutex
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\__msvc_chrono.hpp
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\ratio
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\thread
참고: 포함 파일:               C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\process.h
참고: 포함 파일:                C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_startup.h
참고: 포함 파일:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\math.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\vcruntime_startup.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/IdWrapper.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/TypeIndex.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/ConstexprCrc.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/irange.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/Storage.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/Allocator.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/ThreadLocalDebugInfo.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/UniqueVoidPtr.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/StorageImpl.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/COW.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/COWDeleter.h
참고: 포함 파일:              C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\shared_mutex
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\condition_variable
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/PyObjectSlot.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/HermeticPyObjectTLS.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/PyInterpreter.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/SymIntArrayRef.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/python_stub.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/ExclusivelyOwned.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/TensorImpl.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/InferenceMode.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/AutogradState.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/LocalDispatchKeySet.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/SymbolicShapeMeta.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/DimVector.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/SizesAndStrides.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/WrapDimMinimal.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Flags.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Registry.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Type.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/accumulate.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/safe_numerics.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/UndefinedTensorImpl.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/OptionalArrayRef.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/CheckMemoryFormat.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/TensorOptions.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/DefaultDtype.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/DeprecatedTypePropertiesRegistry.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/DeprecatedTypeProperties.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Generator.h
참고: 포함 파일:             C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\deque
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/GeneratorImpl.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/NamedTensor.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Dimname.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/symbol.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/QuantizerBase.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/TensorAccessor.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/TensorBase.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/C++17.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/ExclusivelyOwnedTensorTraits.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/StorageUtils.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/MethodOperators.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/ATen_fwd.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_addmm_activation_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_autocast_to_full_precision_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_autocast_to_reduced_precision_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_backward_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_coalesced_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj_physical_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dimI_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dimV_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fw_primal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_indices_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_all_true_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_any_true_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_zerotensor_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lazy_clone_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_neg_view_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_size_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_storage_offsets_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_strides_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnz_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_alias_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mask_projection_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_dense_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_bsc_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_bsr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_csc_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_csr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_values_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_version_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/abs_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/absolute_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/acos_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/acosh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/add_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addbmm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addcdiv_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addcmul_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addmm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addmv_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adjoint_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alias_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_as_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_to_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/all_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/allclose_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/amax_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/amin_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/aminmax_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/and_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/angle_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/any_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arccos_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arccosh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arcsin_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arcsinh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctan2_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctan_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctanh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argmax_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argmin_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argsort_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argwhere_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided_scatter_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/asin_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/asinh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atan2_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atan_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atanh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/baddbmm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bernoulli_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bincount_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_and_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_left_shift_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_not_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_or_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_right_shift_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_xor_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bmm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/broadcast_to_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cauchy_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ccol_indices_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ceil_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chalf_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky_inverse_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky_solve_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chunk_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_max_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_min_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clip_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clone_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/coalesce_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col_indices_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conj_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conj_physical_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/contiguous_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copy_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copysign_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/corrcoef_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cos_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/count_nonzero_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cov_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cross_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/crow_indices_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummax_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummin_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumprod_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumsum_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/data_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/deg2rad_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dense_dim_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dequantize_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/det_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/detach_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diag_embed_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diag_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagflat_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_scatter_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diff_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/digamma_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dist_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/div_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/divide_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dot_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dsplit_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/eq_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/equal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erf_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erfc_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erfinv_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exp2_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand_as_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expm1_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exponential_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fill_diagonal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fill_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fix_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flatten_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flip_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fliplr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flipud_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/float_power_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/floor_divide_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/floor_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmax_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmin_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmod_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frac_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frexp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gather_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gcd_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ge_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/geometric_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/geqrf_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ger_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/greater_equal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/greater_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gt_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardshrink_backward_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardshrink_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/heaviside_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histc_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histogram_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hsplit_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hypot_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/i0_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/igamma_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/igammac_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_add_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_copy_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_fill_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_put_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_reduce_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_select_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/indices_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/inner_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/int_repr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/inverse_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_coalesced_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_complex_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_conj_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_distributed_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_floating_point_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_inference_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_leaf_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_neg_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_nonzero_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_pinned_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_same_size_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_set_to_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_signed_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isclose_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isfinite_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isinf_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isnan_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isneginf_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isposinf_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isreal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/istft_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/item_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kron_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kthvalue_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lcm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ldexp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/le_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lerp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/less_equal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/less_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lgamma_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log10_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log1p_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log2_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_normal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_softmax_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logaddexp2_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logaddexp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logcumsumexp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logdet_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_and_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_not_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_or_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_xor_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logit_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logsumexp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lshift_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lt_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lu_solve_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mH_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mT_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_fill_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_scatter_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_select_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matmul_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_H_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_exp_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_power_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/maximum_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mean_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/median_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/min_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/minimum_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mode_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/moveaxis_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/movedim_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/msort_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mul_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multinomial_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multiply_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mv_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mvlgamma_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nan_to_num_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanmean_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanmedian_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanquantile_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nansum_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/narrow_copy_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/narrow_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ne_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/neg_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/negative_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_empty_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_empty_strided_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_full_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_ones_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_zeros_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nextafter_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero_numpy_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero_static_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/norm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/normal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/not_equal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/numpy_T_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/or_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/orgqr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ormqr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/outer_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/output_nr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/permute_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pin_memory_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pinverse_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/polygamma_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/positive_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pow_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/prelu_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/prod_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/put_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_axis_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_scales_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_zero_points_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_scale_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_zero_point_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/qr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/qscheme_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantile_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rad2deg_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/random_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ravel_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reciprocal_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/record_stream_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/refine_names_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/relu_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/remainder_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rename_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/renorm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/repeat_interleave_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/repeat_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/requires_grad_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reshape_as_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reshape_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize_as_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize_as_sparse_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resolve_conj_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resolve_neg_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/retain_grad_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/retains_grad_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/roll_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rot90_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/round_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_indices_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rshift_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rsqrt_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_add_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_reduce_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_scatter_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/set_data_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/set_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sgn_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sigmoid_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sign_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/signbit_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sin_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sinc_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sinh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/size_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_inverse_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_scatter_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slogdet_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softmax_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sort_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_dim_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_mask_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_resize_and_clear_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_resize_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_with_sizes_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sqrt_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/square_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/squeeze_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sspaddmm_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/std_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stft_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stride_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sub_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/subtract_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sum_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sum_to_size_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/svd_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/swapaxes_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/swapdims_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/t_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/take_along_dim_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/take_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tan_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tanh_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tensor_split_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tile_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_dense_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_mkldnn_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_padded_tensor_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_bsc_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_bsr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_csc_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_csr_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/topk_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trace_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/transpose_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triangular_solve_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tril_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triu_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/true_divide_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trunc_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/type_as_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unbind_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unflatten_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/uniform_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_chunk_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_split_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_split_with_sizes_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsqueeze_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/values_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/var_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vdot_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vsplit_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/where_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/xlogy_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/xor_ops.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zero_ops.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/edge.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/hash.h
참고: 포함 파일:        C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\iomanip
참고: 포함 파일:         C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xlocmon
참고: 포함 파일:         C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xloctime
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/forward_grad.h
참고: 포함 파일:       C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\unordered_set
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/NamedTensorUtils.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/NamedTensor.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/TensorNames.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/WrapDimUtils.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/IListRef.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/ivalue_to.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/IListRef_inl.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/List.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/jit_type_base.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/qualified_name.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/type_ptr.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/List_inl.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/ivalue.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/DimVector.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/blob.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/custom_class.h
참고: 포함 파일:               C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\typeindex
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/type_factory.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/dynamic_type.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/ivalue_inl.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Dict.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/order_preserving_flat_hash_map.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Dict_inl.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/functional.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/jit_type.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/rref_interface.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/DeviceGuard.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/DeviceGuardImplInterface.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/InlineDeviceGuard.h
참고: 포함 파일:                 C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/VirtualGuardImpl.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/Event.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/InlineEvent.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/StreamGuard.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/InlineStreamGuard.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/FunctionRef.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Logging.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/logging_is_not_google_glog.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\chrono
참고: 포함 파일:                  C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xfilesystem_abi.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\map
참고: 포함 파일:                  C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xtree
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\set
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/WrapDimUtilsMulti.h
참고: 포함 파일:        C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\bitset
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/VariableHooksInterface.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/autograd_not_implemented_fallback.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/library.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/op_registration/infer_schema.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/function_schema.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/alias_info.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/operator_name.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/dispatch/OperatorOptions.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/function_schema_inl.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/op_registration/op_allowlist.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/dispatch/Dispatcher.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/SequenceNumber.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/KernelFunction.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/BoxedKernel.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/OperatorKernel.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/BoxedKernel_impl.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/stack.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/KernelFunction_impl.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/impl/boxing.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/impl/WrapFunctionIntoFunctor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/CompileTimeFunctionPointer.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/boxing/impl/WrapFunctionIntoRuntimeFunctor.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/dispatch/OperatorEntry.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/flat_hash_map.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/PyHandleCache.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/SafePyObject.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/dispatch/DispatchKeyExtractor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Bitset.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Variadic.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/dispatch/CppSignature.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/dispatch/RegistrationHandleRAII.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/enum_tag.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/record_function.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/LeftRight.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Synchronized.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/grad_mode.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/GradMode.h
참고: 포함 파일:       C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\iostream
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/frontend/function_schema_parser.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/op_registration/op_registration.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/ATenOpList.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/custom_class.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/builtin_function.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/function.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/class_type.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/custom_class_detail.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/custom_function.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/function.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/anomaly_mode.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/grad_mode.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/graph_task.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ThreadLocalState.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/FuncTorchTLS.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/PythonTorchFunctionTLS.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/SavedTensorHooks.h
참고: 포함 파일:         C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\stack
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ThreadLocalPythonObjects.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/PythonDispatcherTLS.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/impl/TorchDispatchModeTLS.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/ThreadLocal.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/input_buffer.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/utils/warnings.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/input_metadata.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ExpandUtils.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Functions.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Context.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/CPUGeneratorImpl.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/MT19937RNGEngine.h
참고: 포함 파일:            C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\math.h
참고: 포함 파일:             C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_math_defines.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/DeviceAccelerator.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/MTIAHooksInterface.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/AcceleratorHooksInterface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/LinalgBackend.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/ATenGeneral.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/LegacyTypeDispatch.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/CUDAHooksInterface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/HIPHooksInterface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/IPUHooksInterface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/MPSHooksInterface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/ORTHooksInterface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/PrivateUse1HooksInterface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/XPUHooksInterface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/QEngine.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/CallOnce.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/env.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/DeviceGuard.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/TensorUtils.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/DimVector.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/EmptyTensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/TensorGeometry.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Utils.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Formatting.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Formatting.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/TracerMode.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Reduction.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/from_blob.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tensor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_add_batch_dim.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_add_batch_dim_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_add_relu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_add_relu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_addmm_activation.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_aminmax.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_aminmax_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_amp_foreach_non_finite_check_and_unscale.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_amp_foreach_non_finite_check_and_unscale_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_amp_update_scale.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_amp_update_scale_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_async.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_async_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_scalar.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_scalar_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_tensor_metadata.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_tensor_metadata_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_autocast_to_full_precision.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_autocast_to_reduced_precision.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_backward.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_batch_norm_impl_index.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_batch_norm_impl_index_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_batch_norm_impl_index_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_batch_norm_impl_index_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Byte.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Byte_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Char.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Char_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Double.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Double_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Float.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Float_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Half.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Half_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Int.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Int_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Long.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Long_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Short.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Short_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cdist_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cdist_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cdist_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cdist_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cholesky_solve_helper.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cholesky_solve_helper_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_choose_qparams_per_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_choose_qparams_per_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_chunk_cat.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_chunk_cat_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_coalesce.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_coalesce_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_coalesced.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_compute_linear_combination.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_compute_linear_combination_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj_physical.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conv_depthwise2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conv_depthwise2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_indices_from_coo_to_csr.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_indices_from_coo_to_csr_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_indices_from_csr_to_coo.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_indices_from_csr_to_coo_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_weight_to_int4pack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_weight_to_int4pack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution_double_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution_double_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution_mode.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution_mode_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_copy_from.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_copy_from_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_copy_from_and_resize.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_copy_from_and_resize_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_compress.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_compress_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_sparse_mm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_sparse_mm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_sparse_mm_search.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_sparse_mm_search_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_ctc_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_ctc_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_ctc_loss_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_ctc_loss_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_ctc_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_ctc_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_init_dropout_state.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_init_dropout_state_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn_flatten_weight.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn_flatten_weight_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_clear_plan_cache.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_clear_plan_cache_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_get_plan_cache_max_size.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_get_plan_cache_max_size_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_get_plan_cache_size.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_get_plan_cache_size_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_set_plan_cache_max_size.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_set_plan_cache_max_size_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cummax_helper.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cummax_helper_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cummin_helper.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cummin_helper_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_debug_has_internal_overlap.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_debug_has_internal_overlap_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dimI.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dimV.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dim_arange.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dim_arange_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dirichlet_grad.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dirichlet_grad_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficient_attention_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficient_attention_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficient_attention_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficient_attention_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficientzerotensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficientzerotensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_dense_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_dense_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_forward_only.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_forward_only_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_per_sample_weights_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_per_sample_weights_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_sparse_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_sparse_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_empty_affine_quantized.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_empty_affine_quantized_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_empty_per_channel_affine_quantized.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_empty_per_channel_affine_quantized_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_euclidean_dist.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_euclidean_dist_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_channel_affine.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_channel_affine_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_channel_affine_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_channel_affine_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_tensor_affine.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_tensor_affine_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_tensor_affine_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_tensor_affine_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_per_tensor_affine_cachemask_tensor_qparams.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_per_tensor_affine_cachemask_tensor_qparams_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_c2c.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_c2c_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_c2r.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_c2r_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_r2c.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_r2c_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fill_mem_eff_dropout_mask.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fill_mem_eff_dropout_mask_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_flash_attention_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_flash_attention_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_flash_attention_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_flash_attention_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foobar.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foobar_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_abs.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_abs_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_acos.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_acos_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_add.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_add_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_addcdiv.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_addcdiv_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_addcmul.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_addcmul_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_asin.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_asin_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_atan.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_atan_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_ceil.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_ceil_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_clamp_max.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_clamp_max_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_clamp_min.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_clamp_min_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_cos.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_cos_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_cosh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_cosh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_div.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_div_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_erf.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_erf_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_erfc.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_erfc_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_exp.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_exp_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_expm1.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_expm1_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_floor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_floor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_frac.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_frac_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_lerp.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_lerp_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_lgamma.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_lgamma_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log10.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log10_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log1p.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log1p_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_maximum.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_maximum_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_minimum.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_minimum_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_mul.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_mul_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_neg.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_neg_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_pow.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_pow_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_reciprocal.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_reciprocal_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_round.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_round_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sigmoid.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sigmoid_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sign.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sign_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sin.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sin_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sinh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sinh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sqrt.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sqrt_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sub.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sub_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_tan.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_tan_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_tanh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_tanh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_trunc.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_trunc_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_zero.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_zero_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_assert_async.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_assert_async_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_assert_scalar.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_assert_scalar_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_sym_constrain_range.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_sym_constrain_range_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_sym_constrain_range_for_size.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_sym_constrain_range_for_size_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_adam.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_adam_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_adamw.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_adamw_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_dropout.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_dropout_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_moving_avg_obs_fq_helper.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_moving_avg_obs_fq_helper_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_sdp_choice.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_sdp_choice_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_sgd.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_sgd_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fw_primal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fw_primal_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fw_primal_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_gather_sparse_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_gather_sparse_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_grid_sampler_2d_cpu_fallback.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_grid_sampler_2d_cpu_fallback_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_grid_sampler_2d_cpu_fallback_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_grid_sampler_2d_cpu_fallback_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_has_compatible_shallow_copy_type.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_has_compatible_shallow_copy_type_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_has_same_storage_numel.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_has_same_storage_numel_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_bin_edges.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_bin_edges_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_from_bin_cts.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_from_bin_cts_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_from_bin_tensors.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_from_bin_tensors_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_index_put_impl.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_index_put_impl_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_indices.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_indices_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_indices_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_int_mm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_int_mm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_all_true.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_any_true.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_zerotensor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lazy_clone.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_check_errors.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_check_errors_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_det.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_det_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_eigh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_eigh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_eigvals.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_eigvals_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_slogdet.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_slogdet_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_solve_ex.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_solve_ex_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_svd.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_svd_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_local_scalar_dense.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_local_scalar_dense_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_log_softmax.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_log_softmax_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_log_softmax_backward_data.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_log_softmax_backward_data_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_logcumsumexp.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_logcumsumexp_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lstm_mps.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lstm_mps_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lu_with_info.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lu_with_info_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dep_token.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dep_token_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dual.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dual_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dual_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dual_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_per_channel_quantized_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_per_channel_quantized_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_per_tensor_quantized_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_per_tensor_quantized_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_scale.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_scale_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_softmax.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_softmax_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_softmax_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_softmax_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mixed_dtypes_linear.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mixed_dtypes_linear_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mkldnn_reshape.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mkldnn_reshape_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mkldnn_transpose.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mkldnn_transpose_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mps_convolution.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mps_convolution_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mps_convolution_transpose.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mps_convolution_transpose_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_batch_norm_legit.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_batch_norm_legit_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_batch_norm_legit_no_training.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_batch_norm_legit_no_training_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_multi_head_attention.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_multi_head_attention_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_neg_view.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_neg_view_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_neg_view_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_from_padded.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_from_padded_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_from_padded_and_nested_example.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_from_padded_and_nested_example_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_jagged_dummy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_jagged_dummy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_lengths.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_lengths_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_offsets.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_offsets_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_ragged_idx.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_ragged_idx_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_values.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_values_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_values_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_values_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_select_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_select_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_sum_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_sum_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_mask.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_mask_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_mask_left_aligned.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_mask_left_aligned_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_tensor_list.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_tensor_list_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_size.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_softmax_with_shape.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_softmax_with_shape_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_storage_offsets.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_strides.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_buffer.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_buffer_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_buffer_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_buffer_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_jagged.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_jagged_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_jagged_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_jagged_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_new_zeros_with_same_feature_meta.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_new_zeros_with_same_feature_meta_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnpack_available.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnpack_available_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnpack_spatial_convolution.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnpack_spatial_convolution_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnz.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pack_padded_sequence.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pack_padded_sequence_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pack_padded_sequence_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pack_padded_sequence_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_circular.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_circular_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_enum.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_enum_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_packed_sequence.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_packed_sequence_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pdist_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pdist_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pdist_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pdist_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pin_memory.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pin_memory_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_prelu_kernel.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_prelu_kernel_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_prelu_kernel_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_prelu_kernel_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_print.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_print_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_propagate_xla_data.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_propagate_xla_data_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_remove_batch_dim.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_remove_batch_dim_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_alias.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_alias_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_alias_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_from_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_from_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_resize_output.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_resize_output_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_rowwise_prune.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_rowwise_prune_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sample_dirichlet.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sample_dirichlet_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_saturate_weight_to_fp16.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_saturate_weight_to_fp16_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_attention_math.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_attention_math_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_cudnn_attention.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_cudnn_attention_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_efficient_attention.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_efficient_attention_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_efficient_attention_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_efficient_attention_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_for_cpu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_for_cpu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_for_cpu_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_for_cpu_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_mm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_mm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_segment_reduce_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_segment_reduce_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_shape_as_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_shape_as_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_slow_conv2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_slow_conv2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_slow_conv2d_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_slow_conv2d_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_draw.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_draw_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_ff.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_ff_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_initialize_state.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_initialize_state_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_scramble.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_scramble_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_softmax.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_softmax_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_softmax_backward_data.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_softmax_backward_data_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_addmm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_addmm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_broadcast_to.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_broadcast_to_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_broadcast_to_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_broadcast_to_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_bsc_tensor_unsafe.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_bsc_tensor_unsafe_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_bsr_tensor_unsafe.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_bsr_tensor_unsafe_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_compressed_tensor_unsafe.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_compressed_tensor_unsafe_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_unsafe.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_unsafe_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_with_dims.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_with_dims_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_with_dims_and_tensors.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_with_dims_and_tensors_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csc_tensor_unsafe.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csc_tensor_unsafe_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_prod.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_prod_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_sum.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_sum_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_tensor_unsafe.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_tensor_unsafe_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_log_softmax.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_log_softmax_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_log_softmax_backward_data.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_log_softmax_backward_data_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mask_projection.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm_reduce_impl.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm_reduce_impl_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm_reduce_impl_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm_reduce_impl_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_semi_structured_linear.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_semi_structured_linear_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_softmax.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_softmax_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_softmax_backward_data.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_softmax_backward_data_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sparse_matmul.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sparse_matmul_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sum.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sum_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sum_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sum_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_spdiags.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_spdiags_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_stack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_stack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_standard_gamma.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_standard_gamma_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_standard_gamma_grad.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_standard_gamma_grad_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_ambiguous_defaults.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_ambiguous_defaults_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch_view.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch_view_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch_view_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch_view_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_check_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_check_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_functorch_fallback.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_functorch_fallback_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_filled_intlist.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_filled_intlist_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_floatlist.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_floatlist_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_intlist.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_intlist_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_parallel_materialize.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_parallel_materialize_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_serialization_subcmul.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_serialization_subcmul_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_string_default.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_string_default_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_warn_in_autograd.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_warn_in_autograd_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_differentiable_gru_cell_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_differentiable_gru_cell_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_differentiable_lstm_cell_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_differentiable_lstm_cell_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_gru_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_gru_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_gru_cell_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_gru_cell_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell_backward_impl.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell_backward_impl_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_cpu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_cpu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_dense.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_bsc.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_bsr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_csc.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_csr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_semi_structured.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_semi_structured_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_transform_bias_rescale_qkv.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_transform_bias_rescale_qkv_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_transformer_encoder_layer_fwd.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_transformer_encoder_layer_fwd_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_trilinear.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_trilinear_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_triton_multi_head_attention.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_triton_multi_head_attention_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_triton_scaled_dot_attention.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_triton_scaled_dot_attention_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unique.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unique_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unique2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unique2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unpack_dual.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unpack_dual_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_index.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_index_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_index_put.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_index_put_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_view.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_view_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bicubic2d_aa.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bicubic2d_aa_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bicubic2d_aa_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bicubic2d_aa_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bilinear2d_aa.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bilinear2d_aa_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bilinear2d_aa_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bilinear2d_aa_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact1d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact1d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_use_cudnn_ctc_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_use_cudnn_ctc_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_use_cudnn_rnn_flatten_weight.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_use_cudnn_rnn_flatten_weight_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_compressed_sparse_indices.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_compressed_sparse_indices_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_bsc_tensor_args.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_bsc_tensor_args_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_bsr_tensor_args.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_bsr_tensor_args_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_compressed_tensor_args.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_compressed_tensor_args_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_coo_tensor_args.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_coo_tensor_args_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_csc_tensor_args.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_csc_tensor_args_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_csr_tensor_args.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_csr_tensor_args_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_values.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_values_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_values_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_version.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_int4pack_mm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_int4pack_mm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_int8pack_mm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_int8pack_mm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_differentiable_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_differentiable_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_interface.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_interface_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_interface_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_interface_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/abs.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/absolute.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/acos.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/acosh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/add.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addbmm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addcdiv.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addcmul.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addmm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addmv.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adjoint.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/affine_grid_generator.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/affine_grid_generator_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/affine_grid_generator_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/affine_grid_generator_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alias.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alias_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alias_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_as.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_tensors.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_tensors_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_to.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/all.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/allclose.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alpha_dropout.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alpha_dropout_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/amax.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/amin.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/aminmax.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/and.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/angle.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/any.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arange.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arange_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arccos.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arccosh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arcsin.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arcsinh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctan.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctan2.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctanh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argmax.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argmin.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argsort.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argwhere.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided_scatter.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/asin.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/asinh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atan.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atan2.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atanh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/baddbmm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bartlett_window.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bartlett_window_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_backward_elemt.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_backward_elemt_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_backward_reduce.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_backward_reduce_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_elemt.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_elemt_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_gather_stats.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_gather_stats_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_gather_stats_with_counts.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_gather_stats_with_counts_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_stats.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_stats_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_update_stats.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_update_stats_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bernoulli.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bilinear.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bilinear_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy_with_logits.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy_with_logits_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bincount.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binomial.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binomial_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_and.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_left_shift.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_not.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_or.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_right_shift.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_xor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/blackman_window.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/blackman_window_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/block_diag.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/block_diag_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bmm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/broadcast_tensors.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/broadcast_tensors_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/broadcast_to.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bucketize.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bucketize_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/can_cast.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/can_cast_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cartesian_prod.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cartesian_prod_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cat.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cat_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cauchy.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ccol_indices.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ccol_indices_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ccol_indices_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cdist.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cdist_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ceil.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/celu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/celu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chain_matmul.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chain_matmul_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chalf.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/channel_shuffle.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/channel_shuffle_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky_inverse.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky_solve.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/choose_qparams_optimized.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/choose_qparams_optimized_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chunk.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_max.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_min.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clip.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clone.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/coalesce.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col2im.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col2im_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col_indices.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col_indices_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col_indices_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/column_stack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/column_stack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/combinations.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/combinations_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/complex.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/complex_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/concat.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/concat_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/concatenate.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/concatenate_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conj.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conj_physical.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/constant_pad_nd.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/constant_pad_nd_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/contiguous.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_depthwise3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_depthwise3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_tbc.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_tbc_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_tbc_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_tbc_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_backward_overrideable.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_backward_overrideable_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_overrideable.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_overrideable_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copy.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copy_sparse_to_sparse.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copy_sparse_to_sparse_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copysign.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/corrcoef.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cos.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosine_embedding_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosine_embedding_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosine_similarity.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosine_similarity_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/count_nonzero.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cov.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cross.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cross_entropy_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cross_entropy_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/crow_indices.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/crow_indices_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/crow_indices_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ctc_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ctc_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_affine_grid_generator.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_affine_grid_generator_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_affine_grid_generator_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_affine_grid_generator_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_batch_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_batch_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_batch_norm_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_batch_norm_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_add_relu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_add_relu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_relu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_relu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_transpose.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_transpose_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_grid_sampler.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_grid_sampler_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_grid_sampler_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_grid_sampler_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_is_acceptable.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_is_acceptable_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummax.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummaxmin_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummaxmin_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummin.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumprod.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumprod_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumprod_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumsum.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumulative_trapezoid.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumulative_trapezoid_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/data.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/deg2rad.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dense_dim.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dequantize.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/det.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/detach.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/detach_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/detach_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diag.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diag_embed.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagflat.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_scatter.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diff.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/digamma.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dist.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/div.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/divide.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dot.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dropout.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dropout_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dsplit.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dstack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dstack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/einsum.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/einsum_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/elu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/elu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/elu_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/elu_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_bag.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_bag_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_dense_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_dense_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_renorm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_renorm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_sparse_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_sparse_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_like.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_like_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_permuted.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_permuted_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_quantized.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_quantized_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_strided.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_strided_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/eq.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/equal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erf.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erfc.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erfinv.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exp2.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand_as.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expm1.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exponential.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/eye.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/eye_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine_cachemask.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine_cachemask_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine_cachemask_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine_cachemask_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine_cachemask.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine_cachemask_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine_cachemask_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine_cachemask_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_fp16_weight.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_fp16_weight_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_fp16_weight_fp32_activation.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_fp16_weight_fp32_activation_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_int8_weight.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_int8_weight_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_int8_weight_fp32_activation.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_int8_weight_fp32_activation_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_quantize_weight.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_quantize_weight_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_pack_gemm_matrix_fp16.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_pack_gemm_matrix_fp16_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_pack_quantized_matrix.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_pack_quantized_matrix_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/feature_alpha_dropout.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/feature_alpha_dropout_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/feature_dropout.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/feature_dropout_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fft.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fft_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fft2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fft2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftfreq.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftfreq_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftshift.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftshift_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfft.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfft_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfft2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfft2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfftn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfftn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifft.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifft_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifft2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifft2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifftn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifftn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifftshift.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifftshift_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfft.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfft_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfft2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfft2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfftn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfftn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfft.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfft_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfft2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfft2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfftn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfftn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfft.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfft_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfft2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfft2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfftfreq.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfftfreq_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfftn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfftn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fill.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fill_diagonal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fix.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flatten.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flatten_dense_tensors.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flatten_dense_tensors_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flip.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fliplr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flipud.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/float_power.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/floor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/floor_divide.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmax.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmin.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmod.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frac.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frexp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frobenius_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frobenius_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/from_file.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/from_file_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/full.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/full_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/full_like.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/full_like_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fused_moving_avg_obs_fake_quant.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fused_moving_avg_obs_fake_quant_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gather.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gather_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gather_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gcd.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ge.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gelu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gelu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gelu_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gelu_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/geometric.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/geqrf.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ger.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_backward_jvp.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_backward_jvp_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_jvp.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_jvp_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gradient.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gradient_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/greater.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/greater_equal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/group_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/group_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gru.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gru_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gru_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gru_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gt.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hamming_window.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hamming_window_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hann_window.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hann_window_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardshrink.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardshrink_backward.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardsigmoid.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardsigmoid_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardsigmoid_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardsigmoid_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardswish.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardswish_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardswish_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardswish_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardtanh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardtanh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardtanh_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardtanh_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/heaviside.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hinge_embedding_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hinge_embedding_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histc.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histogram.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histogramdd.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histogramdd_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hsplit.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hspmm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hspmm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hstack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hstack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/huber_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/huber_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/huber_loss_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/huber_loss_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hypot.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/i0.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/igamma.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/igammac.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/im2col.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/im2col_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/imag.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/imag_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_add.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_copy.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_fill.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_put.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_reduce.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_select.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_select_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_select_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/indices.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/indices_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/indices_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/infinitely_differentiable_gelu_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/infinitely_differentiable_gelu_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/inner.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/instance_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/instance_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/int_repr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/inverse.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_coalesced.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_complex.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_conj.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_distributed.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_floating_point.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_inference.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_leaf.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_neg.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_nonzero.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_pinned.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_same_size.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_set_to.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_signed.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_vulkan_available.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_vulkan_available_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isclose.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isfinite.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isin.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isin_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isinf.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isnan.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isneginf.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isposinf.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isreal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/istft.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/item.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kaiser_window.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kaiser_window_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kl_div.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kl_div_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kron.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kthvalue.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/l1_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/l1_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/layer_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/layer_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lcm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ldexp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/le.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/leaky_relu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/leaky_relu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/leaky_relu_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/leaky_relu_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lerp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/less.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/less_equal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lgamma.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift_fresh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift_fresh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift_fresh_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift_fresh_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cholesky.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cholesky_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cholesky_ex.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cholesky_ex_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cond.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cond_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cross.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cross_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_det.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_det_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_diagonal.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_diagonal_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eig.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eig_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigvals.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigvals_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigvalsh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigvalsh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_householder_product.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_householder_product_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_inv.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_inv_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_inv_ex.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_inv_ex_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_factor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_factor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_factor_ex.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_factor_ex_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_solve.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_solve_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lstsq.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lstsq_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_factor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_factor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_factor_ex.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_factor_ex_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_solve.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_solve_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matmul.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matmul_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_exp.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_exp_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_power.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_power_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_rank.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_rank_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_multi_dot.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_multi_dot_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_pinv.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_pinv_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_qr.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_qr_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_slogdet.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_slogdet_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve_ex.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve_ex_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve_triangular.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve_triangular_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_svd.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_svd_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_svdvals.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_svdvals_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_tensorinv.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_tensorinv_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_tensorsolve.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_tensorsolve_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vander.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vander_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vecdot.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vecdot_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vector_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vector_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linear.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linear_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linear_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linear_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linspace.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linspace_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log10.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log1p.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log2.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_normal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_softmax.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logaddexp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logaddexp2.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logcumsumexp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logdet.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_and.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_not.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_or.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_xor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logit.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logit_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logit_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logspace.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logspace_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logsumexp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lshift.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm_mps_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm_mps_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lt.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lu_solve.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lu_unpack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lu_unpack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mH.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mT.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/margin_ranking_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/margin_ranking_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_fill.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_scatter.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_scatter_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_scatter_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_select.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_select_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_select_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matmul.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matmul_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matmul_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_H.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_exp.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_exp_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_exp_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_power.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool1d_with_indices.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool1d_with_indices_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_with_indices.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_with_indices_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_with_indices_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_with_indices_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d_with_indices.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d_with_indices_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d_with_indices_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d_with_indices_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_unpool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_unpool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_unpool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_unpool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/maximum.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mean.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/median.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/meshgrid.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/meshgrid_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/min.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/minimum.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_batch_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_batch_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_batch_norm_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_batch_norm_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_add_relu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_add_relu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_relu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_relu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_transpose.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_transpose_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_depthwise_convolution.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_depthwise_convolution_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_rnn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_rnn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_rnn_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_rnn_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mish.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mish_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mish_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mish_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_adaptive_avg_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_adaptive_avg_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_adaptive_avg_pool2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_adaptive_avg_pool2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_convolution.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_convolution_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward_input.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward_input_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward_weights.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward_weights_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_reorder_conv2d_weight.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_reorder_conv2d_weight_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_reorder_conv3d_weight.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_reorder_conv3d_weight_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_rnn_layer.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_rnn_layer_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_rnn_layer_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_rnn_layer_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mode.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/moveaxis.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/movedim.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mps_convolution_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mps_convolution_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mps_convolution_transpose_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mps_convolution_transpose_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mse_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mse_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mse_loss_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mse_loss_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/msort.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mul.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multi_margin_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multi_margin_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multi_margin_loss_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multi_margin_loss_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multinomial.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multiply.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mv.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mvlgamma.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nan_to_num.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanmean.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanmedian.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanquantile.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nansum.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/narrow.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/narrow_copy.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_batch_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_batch_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_batch_norm_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_batch_norm_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_channel_shuffle.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_channel_shuffle_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_dropout.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_dropout_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_dropout_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_dropout_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_group_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_group_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_group_norm_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_group_norm_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_layer_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_layer_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_layer_norm_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_layer_norm_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ne.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/neg.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/negative.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nested_to_padded_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nested_to_padded_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_empty.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_empty_strided.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_full.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_ones.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_zeros.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nextafter.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_nd.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_nd_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero_numpy.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero_static.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/norm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/norm_except_dim.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/norm_except_dim_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/normal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/not_equal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nuclear_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nuclear_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/numpy_T.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/one_hot.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/one_hot_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ones.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ones_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ones_like.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ones_like_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/or.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/orgqr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ormqr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/outer.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/output_nr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pad.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pad_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pad_sequence.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pad_sequence_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pairwise_distance.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pairwise_distance_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pdist.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pdist_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/permute.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/permute_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/permute_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pin_memory.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pinverse.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pixel_shuffle.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pixel_shuffle_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pixel_unshuffle.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pixel_unshuffle_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/poisson.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/poisson_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/poisson_nll_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/poisson_nll_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/polar.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/polar_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/polygamma.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/positive.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pow.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/prelu.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/prod.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/promote_types.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/promote_types_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/put.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_axis.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_scales.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_zero_points.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_scale.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_zero_point.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/qr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/qscheme.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantile.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_channel.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_channel_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_tensor_dynamic.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_tensor_dynamic_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_batch_norm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_batch_norm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_gru_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_gru_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_lstm_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_lstm_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_rnn_relu_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_rnn_relu_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_rnn_tanh_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_rnn_tanh_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rad2deg.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rand.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rand_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rand_like.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rand_like_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randint.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randint_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randint_like.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randint_like_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randn.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randn_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randn_like.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randn_like_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/random.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randperm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randperm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/range.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/range_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ravel.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/real.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/real_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reciprocal.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/record_stream.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/refine_names.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad1d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad1d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/relu.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/relu6.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/relu6_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/remainder.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rename.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/renorm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/repeat.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/repeat_interleave.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad1d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad1d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/requires_grad.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reshape.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reshape_as.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize_as.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize_as_sparse.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resolve_conj.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resolve_neg.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/result_type.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/result_type_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/retain_grad.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/retains_grad.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_relu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_relu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_relu_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_relu_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_tanh.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_tanh_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_tanh_cell.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_tanh_cell_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/roll.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rot90.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/round.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_indices.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_indices_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_indices_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_stack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_stack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu_with_noise.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu_with_noise_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu_with_noise_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu_with_noise_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rshift.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rsqrt.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rsub.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rsub_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scalar_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scalar_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scaled_dot_product_attention.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scaled_dot_product_attention_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_add.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_reduce.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/searchsorted.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/searchsorted_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/segment_reduce.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/segment_reduce_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_scatter.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/selu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/selu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/set.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/set_data.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sgn.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sigmoid.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sigmoid_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sigmoid_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sign.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/signbit.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/silu.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/silu_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/silu_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/silu_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sin.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sinc.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sinh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/size.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_inverse.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_scatter.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slogdet.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv3d_forward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv3d_forward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_dilated2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_dilated2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_dilated3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_dilated3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_transpose2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_transpose2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_transpose3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_transpose3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smooth_l1_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smooth_l1_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smooth_l1_loss_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smooth_l1_loss_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/soft_margin_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/soft_margin_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/soft_margin_loss_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/soft_margin_loss_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softmax.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softplus.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softplus_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softplus_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softplus_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softshrink.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softshrink_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softshrink_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softshrink_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sort.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_bsc_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_bsc_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_bsr_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_bsr_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_compressed_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_compressed_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_coo_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_coo_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_csc_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_csc_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_csr_tensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_csr_tensor_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_dim.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_mask.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_resize.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_resize_and_clear.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_sampled_addmm.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_sampled_addmm_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_airy_ai.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_airy_ai_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_j0.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_j0_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_j1.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_j1_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_y0.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_y0_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_y1.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_y1_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_t.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_t_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_u.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_u_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_v.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_v_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_w.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_w_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_digamma.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_digamma_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_entr.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_entr_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erf.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erf_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfc.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfc_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfcx.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfcx_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfinv.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfinv_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_exp2.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_exp2_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_expit.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_expit_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_expm1.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_expm1_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammainc.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammainc_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammaincc.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammaincc_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammaln.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammaln_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_hermite_polynomial_h.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_hermite_polynomial_h_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_hermite_polynomial_he.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_hermite_polynomial_he_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i0.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i0_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i0e.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i0e_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i1.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i1_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i1e.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i1e_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_laguerre_polynomial_l.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_laguerre_polynomial_l_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_legendre_polynomial_p.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_legendre_polynomial_p_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log1p.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log1p_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log_ndtr.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log_ndtr_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log_softmax.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log_softmax_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_logit.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_logit_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_logsumexp.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_logsumexp_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_i0.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_i0_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_i1.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_i1_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_k0.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_k0_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_k1.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_k1_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_multigammaln.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_multigammaln_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_ndtr.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_ndtr_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_ndtri.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_ndtri_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_polygamma.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_polygamma_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_psi.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_psi_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_round.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_round_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_scaled_modified_bessel_k0.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_scaled_modified_bessel_k0_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_scaled_modified_bessel_k1.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_scaled_modified_bessel_k1_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_t.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_t_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_u.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_u_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_v.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_v_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_w.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_w_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_sinc.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_sinc_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_softmax.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_softmax_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_spherical_bessel_j0.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_spherical_bessel_j0_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_xlog1py.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_xlog1py_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_xlogy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_xlogy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_zeta.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_zeta_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_with_sizes.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_with_sizes_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_with_sizes_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sqrt.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/square.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/squeeze.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/squeeze_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/squeeze_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sspaddmm.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/std.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/std_mean.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/std_mean_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stft.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stride.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sub.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/subtract.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sum.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sum_to_size.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/svd.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/swapaxes.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/swapdims.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_constrain_range.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_constrain_range_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_constrain_range_for_size.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_constrain_range_for_size_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_numel.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_numel_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_size.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_size_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_storage_offset.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_storage_offset_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_stride.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_stride_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/t.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/t_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/t_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/take.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/take_along_dim.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tan.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tanh.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tanh_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tanh_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tensor_split.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tensordot.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tensordot_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/thnn_conv2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/thnn_conv2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/threshold.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/threshold_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/threshold_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/threshold_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tile.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_dense.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_dense_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_dense_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_mkldnn.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_mkldnn_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_mkldnn_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_padded_tensor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_bsc.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_bsr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_csc.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_csr.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/topk.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trace.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trace_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trace_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/transpose.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/transpose_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/transpose_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trapezoid.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trapezoid_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trapz.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trapz_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triangular_solve.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tril.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tril_indices.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tril_indices_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triplet_margin_loss.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triplet_margin_loss_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triu.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triu_indices.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triu_indices_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/true_divide.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trunc.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/type_as.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unbind.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unbind_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unbind_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unflatten.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unflatten_dense_tensors.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unflatten_dense_tensors_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/uniform.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_consecutive.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_consecutive_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_dim.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_dim_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_dim_consecutive.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_dim_consecutive_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_chunk.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_split.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_split_with_sizes.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsqueeze.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsqueeze_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsqueeze_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bicubic2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bicubic2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bicubic2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bicubic2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bilinear2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bilinear2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bilinear2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bilinear2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_linear1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_linear1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_linear1d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_linear1d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest1d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest1d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest1d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest1d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest2d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest2d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest2d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest2d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_trilinear3d.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_trilinear3d_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_trilinear3d_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_trilinear3d_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/value_selecting_reduction_backward.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/value_selecting_reduction_backward_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/values.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/values_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/values_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vander.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vander_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/var.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/var_mean.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/var_mean_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vdot.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_complex.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_complex_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_complex_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_complex_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_real.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_real_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_real_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_real_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_copy.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_copy_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vsplit.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vstack.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vstack_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/where.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/xlogy.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/xor.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zero.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zeros.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zeros_ops.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zeros_like.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zeros_like_ops.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/NestedTensorImpl.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/MemoryOverlap.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/saved_variable.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/saved_variable_hooks.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/variadic.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/variable_info.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/cuda.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/dataloader.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/dataloader/stateful.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/dataloader/base.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/dataloader_options.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/arg.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/types.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ATen.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Device.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Dispatch.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Formatting.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/NamedTensor.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ScalarOps.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/TensorIndexing.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/NativeFunctions.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_adaptive_avg_pool3d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_add_batch_dim_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_add_relu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_addmm_activation_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_addmm_activation_meta.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/TensorIterator.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/TensorMeta.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/strides.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Range.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/core/DynamicCast.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/Load.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_aminmax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_amp_foreach_non_finite_check_and_unscale_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_amp_update_scale_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_async_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_scalar_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_assert_tensor_metadata_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_autocast_to_full_precision_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_autocast_to_reduced_precision_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_batch_norm_impl_index_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_batch_norm_impl_index_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Byte_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Char_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Double_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Float_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Half_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Int_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Long_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cast_Short_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cdist_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cdist_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cholesky_solve_helper_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_choose_qparams_per_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_chunk_cat_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_coalesce_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_coalesced_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_compute_linear_combination_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conj_physical_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_conv_depthwise2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_indices_from_coo_to_csr_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_indices_from_coo_to_csr_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_indices_from_csr_to_coo_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_indices_from_csr_to_coo_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convert_weight_to_int4pack_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution_double_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_convolution_mode_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_copy_from_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_copy_from_and_resize_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_compress_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_sparse_mm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cslt_sparse_mm_search_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_ctc_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_ctc_loss_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_ctc_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_init_dropout_state_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cudnn_rnn_flatten_weight_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_clear_plan_cache_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_get_plan_cache_max_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_get_plan_cache_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cufft_set_plan_cache_max_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cummax_helper_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_cummin_helper_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_debug_has_internal_overlap_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dimI_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dimV_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dim_arange_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_dirichlet_grad_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficient_attention_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficient_attention_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_efficientzerotensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_dense_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_forward_only_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_per_sample_weights_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_embedding_bag_sparse_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_empty_affine_quantized_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_empty_per_channel_affine_quantized_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_euclidean_dist_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_channel_affine_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_channel_affine_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_tensor_affine_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_learnable_per_tensor_affine_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fake_quantize_per_tensor_affine_cachemask_tensor_qparams_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_c2c_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_c2r_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fft_r2c_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fill_mem_eff_dropout_mask_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_flash_attention_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_flash_attention_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foobar_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_abs_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_acos_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_add_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_addcdiv_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_addcmul_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_asin_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_atan_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_ceil_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_clamp_max_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_clamp_min_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_cos_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_cosh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_div_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_erf_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_erfc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_exp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_expm1_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_floor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_frac_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_lerp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_lgamma_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log10_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log1p_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_log2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_maximum_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_minimum_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_mul_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_neg_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_pow_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_reciprocal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_round_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sigmoid_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sign_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sin_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sinh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sqrt_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_sub_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_tan_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_tanh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_trunc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_foreach_zero_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_assert_async_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_assert_scalar_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_sym_constrain_range_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_functional_sym_constrain_range_for_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_adam_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_adamw_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_dropout_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_moving_avg_obs_fq_helper_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_sdp_choice_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fused_sgd_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fw_primal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_fw_primal_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_gather_sparse_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_grid_sampler_2d_cpu_fallback_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_grid_sampler_2d_cpu_fallback_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_has_compatible_shallow_copy_type_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_has_same_storage_numel_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_bin_edges_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_from_bin_cts_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_histogramdd_from_bin_tensors_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_index_put_impl_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_indices_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_int_mm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_all_true_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_any_true_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_is_zerotensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lazy_clone_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_check_errors_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_det_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_det_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_eigh_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_eigh_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_eigvals_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_slogdet_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_slogdet_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_solve_ex_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_solve_ex_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_svd_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_linalg_svd_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_local_scalar_dense_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_log_softmax_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_log_softmax_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_log_softmax_backward_data_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_log_softmax_backward_data_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_logcumsumexp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lstm_mps_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_lu_with_info_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dep_token_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dual_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_dual_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_per_channel_quantized_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_make_per_tensor_quantized_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_scale_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_softmax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_masked_softmax_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mixed_dtypes_linear_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mkldnn_reshape_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mkldnn_transpose_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mps_convolution_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_mps_convolution_transpose_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_batch_norm_legit_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_batch_norm_legit_no_training_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_native_multi_head_attention_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_neg_view_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_neg_view_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_from_padded_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_from_padded_and_nested_example_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_jagged_dummy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_lengths_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_offsets_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_ragged_idx_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_values_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_get_values_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_select_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_sum_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_mask_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_mask_left_aligned_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_from_tensor_list_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_softmax_with_shape_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_storage_offsets_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_tensor_strides_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_buffer_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_buffer_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_jagged_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nested_view_from_jagged_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_new_zeros_with_same_feature_meta_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnpack_available_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnpack_spatial_convolution_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_nnz_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pack_padded_sequence_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pack_padded_sequence_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_circular_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_enum_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pad_packed_sequence_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pdist_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pdist_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_pin_memory_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_prelu_kernel_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_prelu_kernel_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_print_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_propagate_xla_data_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_remove_batch_dim_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_alias_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_alias_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_reshape_from_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_resize_output_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_rowwise_prune_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sample_dirichlet_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_saturate_weight_to_fp16_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_attention_math_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_cudnn_attention_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_efficient_attention_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_efficient_attention_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_for_cpu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_dot_product_flash_attention_for_cpu_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_scaled_mm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_segment_reduce_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_shape_as_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_slow_conv2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_slow_conv2d_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_draw_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_ff_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_initialize_state_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sobol_engine_scramble_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_softmax_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_softmax_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_softmax_backward_data_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_softmax_backward_data_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_addmm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_broadcast_to_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_broadcast_to_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_bsc_tensor_unsafe_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_bsr_tensor_unsafe_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_compressed_tensor_unsafe_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_unsafe_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_with_dims_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_coo_tensor_with_dims_and_tensors_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csc_tensor_unsafe_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_prod_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_sum_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_csr_tensor_unsafe_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_log_softmax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_log_softmax_backward_data_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mask_projection_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm_reduce_impl_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_mm_reduce_impl_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_semi_structured_linear_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_softmax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_softmax_backward_data_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sparse_matmul_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sum_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_sparse_sum_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_spdiags_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_stack_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_standard_gamma_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_standard_gamma_grad_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_ambiguous_defaults_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch_view_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_autograd_multiple_dispatch_view_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_check_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_functorch_fallback_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_filled_intlist_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_floatlist_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_optional_intlist_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_parallel_materialize_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_serialization_subcmul_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_string_default_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_test_warn_in_autograd_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_differentiable_gru_cell_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_differentiable_lstm_cell_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_gru_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_gru_cell_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_thnn_fused_lstm_cell_backward_impl_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_cpu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_dense_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_bsc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_bsr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_csc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_csr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_to_sparse_semi_structured_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_transform_bias_rescale_qkv_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_transformer_encoder_layer_fwd_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_trilinear_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_triton_multi_head_attention_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_triton_scaled_dot_attention_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unique_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unique2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unpack_dual_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_index_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_index_put_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_unsafe_view_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bicubic2d_aa_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bicubic2d_aa_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bicubic2d_aa_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bicubic2d_aa_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bilinear2d_aa_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bilinear2d_aa_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bilinear2d_aa_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_bilinear2d_aa_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact1d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact1d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact1d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact1d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact2d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact2d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact3d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact3d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact3d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_upsample_nearest_exact3d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_use_cudnn_ctc_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_use_cudnn_rnn_flatten_weight_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_compressed_sparse_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_bsc_tensor_args_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_bsr_tensor_args_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_compressed_tensor_args_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_coo_tensor_args_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_csc_tensor_args_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_validate_sparse_csr_tensor_args_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_values_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_values_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_version_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_int4pack_mm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_int8pack_mm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_differentiable_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_interface_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/_weight_norm_interface_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/abs_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/absolute_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/acos_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/acos_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/acosh_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/acosh_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool1d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_avg_pool3d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool1d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool2d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool2d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool3d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool3d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool3d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adaptive_max_pool3d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/add_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/add_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addbmm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addcdiv_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addcdiv_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addcmul_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addcmul_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addmm_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addmm_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addmv_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addmv_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/addr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/adjoint_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/affine_grid_generator_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/affine_grid_generator_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alias_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alias_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_as_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_tensors_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/align_to_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/all_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/all_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/allclose_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/alpha_dropout_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/amax_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/amax_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/amin_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/amin_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/aminmax_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/aminmax_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/and_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/angle_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/any_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/any_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arange_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arccos_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arccosh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arcsin_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arcsinh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctan_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctan2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/arctanh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argmax_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argmax_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argmin_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argmin_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argsort_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/argwhere_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/as_strided_scatter_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/asin_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/asin_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/asinh_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/asinh_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atan_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atan_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atan2_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atan2_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atanh_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atanh_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_1d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/atleast_3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool1d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool2d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool2d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool3d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool3d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool3d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/avg_pool3d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/baddbmm_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/baddbmm_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bartlett_window_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_backward_elemt_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_backward_reduce_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_elemt_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_gather_stats_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_gather_stats_with_counts_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_stats_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/batch_norm_update_stats_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bernoulli_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bilinear_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binary_cross_entropy_with_logits_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bincount_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/binomial_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_and_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_and_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_left_shift_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_left_shift_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_not_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_not_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_or_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_or_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_right_shift_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_right_shift_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_xor_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bitwise_xor_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/blackman_window_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/block_diag_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bmm_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bmm_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/broadcast_tensors_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/broadcast_to_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/bucketize_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/can_cast_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cartesian_prod_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cat_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cat_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cauchy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ccol_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ccol_indices_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cdist_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ceil_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ceil_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/celu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chain_matmul_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chalf_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/channel_shuffle_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky_inverse_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cholesky_solve_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/choose_qparams_optimized_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/chunk_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_max_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_max_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_min_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clamp_min_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clip_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/clone_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/coalesce_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col2im_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/col_indices_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/column_stack_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/combinations_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/complex_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/concat_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/concatenate_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conj_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conj_physical_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/constant_pad_nd_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/contiguous_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv1d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_depthwise3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_tbc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_tbc_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose1d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/conv_transpose3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_backward_overrideable_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/convolution_overrideable_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copy_sparse_to_sparse_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copysign_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/copysign_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/corrcoef_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cos_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cos_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosh_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosh_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosine_embedding_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cosine_similarity_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/count_nonzero_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cov_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cross_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cross_entropy_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/crow_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/crow_indices_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ctc_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_affine_grid_generator_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_affine_grid_generator_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_batch_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_batch_norm_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_add_relu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_relu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_convolution_transpose_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_grid_sampler_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_grid_sampler_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cudnn_is_acceptable_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummaxmin_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cummin_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumprod_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumprod_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumprod_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumsum_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumsum_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/cumulative_trapezoid_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/data_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/deg2rad_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dense_dim_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dequantize_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/det_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/detach_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/detach_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diag_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diag_embed_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagflat_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diagonal_scatter_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/diff_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/digamma_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/digamma_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dist_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/div_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/div_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/divide_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dot_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dropout_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dsplit_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/dstack_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/einsum_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/elu_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/elu_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/elu_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/elu_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_bag_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_dense_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_renorm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/embedding_sparse_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_like_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_permuted_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_quantized_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/empty_strided_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/eq_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/eq_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/equal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erf_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erf_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erfc_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erfc_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erfinv_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/erfinv_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exp_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exp_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exp2_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exp2_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand_as_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expand_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expm1_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/expm1_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/exponential_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/eye_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine_cachemask_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_channel_affine_cachemask_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine_cachemask_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fake_quantize_per_tensor_affine_cachemask_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_fp16_weight_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_fp16_weight_fp32_activation_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_int8_weight_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_int8_weight_fp32_activation_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_linear_quantize_weight_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_pack_gemm_matrix_fp16_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fbgemm_pack_quantized_matrix_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/feature_alpha_dropout_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/feature_dropout_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fft_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fft2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftfreq_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_fftshift_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfft_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfft2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_hfftn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifft_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifft2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifftn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ifftshift_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfft_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfft2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_ihfftn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfft_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfft2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_irfftn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfft_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfft2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfftfreq_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fft_rfftn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fill_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fill_diagonal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fix_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flatten_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flatten_dense_tensors_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flip_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fliplr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/flipud_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/float_power_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/floor_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/floor_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/floor_divide_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmax_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmax_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmin_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmin_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmod_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fmod_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frac_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frac_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool2d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool2d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool3d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool3d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fractional_max_pool3d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frexp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/frobenius_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/from_file_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/full_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/full_like_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/fused_moving_avg_obs_fake_quant_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gather_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gather_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gather_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gcd_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gcd_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ge_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ge_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gelu_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gelu_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gelu_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gelu_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/geometric_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/geqrf_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ger_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_backward_jvp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/glu_jvp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gradient_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/greater_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/greater_equal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/grid_sampler_3d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/group_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gru_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gru_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gt_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/gt_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hamming_window_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hann_window_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardshrink_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardshrink_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardshrink_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardshrink_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardsigmoid_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardsigmoid_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardsigmoid_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardsigmoid_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardswish_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardswish_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardtanh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hardtanh_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/heaviside_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/heaviside_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hinge_embedding_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histogram_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/histogramdd_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hsplit_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hspmm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hstack_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/huber_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/huber_loss_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hypot_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/hypot_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/i0_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/i0_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/igamma_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/igamma_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/igammac_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/igammac_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/im2col_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/imag_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_add_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_add_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_copy_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_copy_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_fill_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_put_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_reduce_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_reduce_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_select_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/index_select_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/indices_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/infinitely_differentiable_gelu_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/inner_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/instance_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/int_repr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/inverse_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_coalesced_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_complex_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_conj_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_distributed_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_floating_point_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_inference_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_leaf_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_neg_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_nonzero_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_pinned_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_same_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_set_to_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_signed_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/is_vulkan_available_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isclose_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isfinite_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isin_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isin_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isinf_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isnan_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isneginf_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isneginf_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isposinf_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isposinf_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/isreal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/istft_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/item_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kaiser_window_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kl_div_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kron_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/kthvalue_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/l1_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/layer_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lcm_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lcm_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ldexp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/le_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/le_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/leaky_relu_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/leaky_relu_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/leaky_relu_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/leaky_relu_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lerp_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lerp_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/less_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/less_equal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lgamma_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lgamma_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift_fresh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lift_fresh_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cholesky_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cholesky_ex_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cholesky_ex_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cond_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cross_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_cross_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_det_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_diagonal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eig_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigvals_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_eigvalsh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_householder_product_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_inv_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_inv_ex_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_inv_ex_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_factor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_factor_ex_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_factor_ex_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_solve_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_ldl_solve_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lstsq_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_factor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_factor_ex_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_factor_ex_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_solve_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_lu_solve_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matmul_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_exp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_power_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_matrix_rank_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_multi_dot_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_pinv_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_qr_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_qr_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_slogdet_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve_ex_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_solve_triangular_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_svd_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_svdvals_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_tensorinv_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_tensorsolve_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vander_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vecdot_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vector_norm_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linalg_vector_norm_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linear_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linear_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/linspace_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log10_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log10_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log1p_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log1p_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log2_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log2_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_normal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_sigmoid_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/log_softmax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logaddexp_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logaddexp_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logaddexp2_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logaddexp2_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logcumsumexp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logdet_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_and_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_not_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_or_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logical_xor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logit_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logit_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logit_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logspace_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/logsumexp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lshift_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lstm_mps_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lt_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lt_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lu_solve_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lu_unpack_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/lu_unpack_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mH_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mT_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/margin_ranking_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_fill_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_scatter_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_scatter_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_select_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/masked_select_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matmul_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matmul_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_H_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_exp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_exp_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/matrix_power_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool1d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool1d_with_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_with_indices_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_with_indices_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_with_indices_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool2d_with_indices_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d_with_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_pool3d_with_indices_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_unpool2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/max_unpool3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/maximum_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/maximum_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mean_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mean_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/median_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/meshgrid_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/min_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/min_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/minimum_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/minimum_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_batch_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_batch_norm_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_add_relu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_relu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_convolution_transpose_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_depthwise_convolution_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_rnn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/miopen_rnn_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mish_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mish_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mish_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_adaptive_avg_pool2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_adaptive_avg_pool2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_convolution_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward_input_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_linear_backward_weights_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_max_pool3d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_reorder_conv2d_weight_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_reorder_conv3d_weight_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_rnn_layer_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mkldnn_rnn_layer_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mm_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mm_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mode_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/moveaxis_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/movedim_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mps_convolution_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mps_convolution_transpose_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mse_loss_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mse_loss_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mse_loss_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/msort_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mul_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mul_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multi_margin_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multi_margin_loss_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multilabel_margin_loss_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multinomial_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/multiply_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mv_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/mvlgamma_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nan_to_num_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanmean_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanmedian_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nanquantile_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nansum_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/narrow_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/narrow_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_batch_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_batch_norm_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_channel_shuffle_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_dropout_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_dropout_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_group_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_group_norm_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_layer_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_layer_norm_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/native_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ne_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ne_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/neg_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/neg_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/negative_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nested_to_padded_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_empty_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_empty_strided_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_full_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_ones_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/new_zeros_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nextafter_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nextafter_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss2d_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_forward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_forward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nll_loss_nd_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero_numpy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nonzero_static_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/norm_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/norm_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/norm_except_dim_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/normal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/not_equal_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/nuclear_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/numpy_T_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/one_hot_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ones_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ones_like_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/or_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/orgqr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ormqr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/outer_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/output_nr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pad_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pad_sequence_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pairwise_distance_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pdist_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/permute_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/permute_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pin_memory_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pinverse_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pixel_shuffle_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pixel_unshuffle_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/poisson_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/poisson_nll_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/polar_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/polygamma_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/polygamma_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/positive_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pow_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/pow_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/prelu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/prod_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/prod_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/promote_types_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/put_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_axis_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_scales_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_per_channel_zero_points_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_scale_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/q_zero_point_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/qr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/qscheme_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantile_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_channel_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantize_per_tensor_dynamic_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_batch_norm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_gru_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_lstm_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool1d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_max_pool3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_rnn_relu_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/quantized_rnn_tanh_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rad2deg_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rand_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rand_like_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randint_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randint_like_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randn_like_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/random_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/randperm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/range_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/ravel_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/real_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reciprocal_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reciprocal_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/record_stream_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/refine_names_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad1d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad1d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad1d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad1d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad3d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad3d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad3d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reflection_pad3d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/relu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/relu6_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/remainder_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/remainder_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rename_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/renorm_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/renorm_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/repeat_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/repeat_interleave_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad1d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad1d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad1d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad1d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad2d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad3d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad3d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/replication_pad3d_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/requires_grad_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reshape_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/reshape_as_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize_as_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resize_as_sparse_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resolve_conj_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/resolve_neg_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/result_type_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/retain_grad_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/retains_grad_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_relu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_relu_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_tanh_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rnn_tanh_cell_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/roll_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rot90_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/round_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/round_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_indices_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/row_stack_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu_with_noise_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rrelu_with_noise_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rshift_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rsqrt_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rsqrt_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/rsub_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scalar_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scaled_dot_product_attention_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_add_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_add_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_reduce_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/scatter_reduce_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/searchsorted_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/segment_reduce_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/select_scatter_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/selu_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/set_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/set_data_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sgn_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sgn_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sigmoid_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sigmoid_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sigmoid_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sigmoid_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sign_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sign_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/signbit_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/signbit_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/silu_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/silu_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/silu_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/silu_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sin_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sin_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sinc_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sinc_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sinh_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sinh_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_inverse_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slice_scatter_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slogdet_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv3d_forward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_dilated2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_dilated3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_transpose2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_transpose2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/slow_conv_transpose3d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smooth_l1_loss_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smooth_l1_loss_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/smooth_l1_loss_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/soft_margin_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/soft_margin_loss_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softmax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softplus_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softplus_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softplus_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softplus_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softshrink_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softshrink_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softshrink_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/softshrink_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sort_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sort_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_bsc_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_bsr_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_compressed_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_coo_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_csc_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_csr_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_dim_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_mask_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_resize_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_resize_and_clear_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sparse_sampled_addmm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_airy_ai_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_airy_ai_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_j0_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_j0_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_j1_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_j1_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_y0_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_y0_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_y1_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_bessel_y1_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_t_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_t_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_u_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_u_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_v_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_v_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_w_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_chebyshev_polynomial_w_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_digamma_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_entr_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_entr_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erf_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfcx_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfcx_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_erfinv_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_exp2_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_expit_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_expm1_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammainc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammaincc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_gammaln_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_hermite_polynomial_h_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_hermite_polynomial_h_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_hermite_polynomial_he_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_hermite_polynomial_he_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i0_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i0e_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i0e_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i1_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i1_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i1e_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_i1e_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_laguerre_polynomial_l_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_laguerre_polynomial_l_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_legendre_polynomial_p_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_legendre_polynomial_p_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log1p_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log_ndtr_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log_ndtr_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_log_softmax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_logit_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_logsumexp_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_i0_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_i0_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_i1_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_i1_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_k0_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_k0_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_k1_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_modified_bessel_k1_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_multigammaln_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_ndtr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_ndtri_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_ndtri_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_polygamma_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_psi_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_round_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_scaled_modified_bessel_k0_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_scaled_modified_bessel_k0_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_scaled_modified_bessel_k1_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_scaled_modified_bessel_k1_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_t_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_t_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_u_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_u_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_v_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_v_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_w_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_shifted_chebyshev_polynomial_w_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_sinc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_softmax_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_spherical_bessel_j0_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_spherical_bessel_j0_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_xlog1py_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_xlog1py_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_xlogy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_zeta_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/special_zeta_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_with_sizes_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/split_with_sizes_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sqrt_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sqrt_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/square_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/squeeze_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/squeeze_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sspaddmm_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stack_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/std_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/std_mean_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stft_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/stride_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sub_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sub_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/subtract_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sum_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sum_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sum_to_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/svd_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/swapaxes_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/swapdims_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_constrain_range_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_constrain_range_for_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_numel_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_size_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_storage_offset_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/sym_stride_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/t_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/t_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/take_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/take_along_dim_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tan_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tan_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tanh_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tanh_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tanh_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tanh_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tensor_split_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tensordot_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/thnn_conv2d_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/threshold_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/threshold_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/threshold_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/threshold_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tile_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_dense_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_dense_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_mkldnn_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_mkldnn_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_padded_tensor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_bsc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_bsr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_csc_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/to_sparse_csr_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/topk_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/topk_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trace_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trace_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/transpose_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/transpose_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trapezoid_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trapz_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triangular_solve_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triangular_solve_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tril_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tril_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/tril_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triplet_margin_loss_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triu_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triu_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/triu_indices_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/true_divide_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trunc_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/trunc_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/type_as_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unbind_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unbind_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unflatten_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unflatten_dense_tensors_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unfold_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/uniform_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_consecutive_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_dim_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unique_dim_consecutive_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_chunk_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_split_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsafe_split_with_sizes_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsqueeze_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/unsqueeze_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bicubic2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bicubic2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bicubic2d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bicubic2d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bilinear2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bilinear2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bilinear2d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_bilinear2d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_linear1d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_linear1d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_linear1d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_linear1d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest1d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest1d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest1d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest1d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest2d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest2d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest2d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest2d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest3d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest3d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest3d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_nearest3d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_trilinear3d_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_trilinear3d_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_trilinear3d_backward_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/upsample_trilinear3d_backward_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/value_selecting_reduction_backward_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/values_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/values_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vander_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/var_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/var_mean_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vdot_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_complex_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_complex_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_real_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_as_real_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/view_copy_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vsplit_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/vstack_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/where_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/xlogy_native.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/xlogy_meta.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/xor_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zero_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zeros_native.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ops/zeros_like_native.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/TensorOperators.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Version.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/Scalar.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/UnsafeFromTH.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/generated/variable_factories.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/api/include/torch/detail/TensorDataContainer.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/detail/data_shuttle.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/detail/queue.h
참고: 포함 파일:         C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\queue
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/detail/sequencers.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/iterator.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/samplers/random.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/samplers/base.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/worker_exception.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/dataloader/stateless.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/datasets.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/datasets/base.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/example.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/datasets/chunk.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/datasets/stateful.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/samplers.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/samplers/custom_batch_request.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/samplers/distributed.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/samplers/sequential.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/samplers/serialize.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/serialize/archive.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/serialize/input-archive.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/api/module.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/api/object.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/api/method.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/api/include/torch/imethod.h
참고: 포함 파일:             C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/api/function_impl.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/ir/ir.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/ir/attributes.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/ir/graph_node_list.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/ir/named_value.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/frontend/source_range.h
참고: 포함 파일:                 C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\regex
참고: 포함 파일:                  C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\locale
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xlocbuf
참고: 포함 파일:                   C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\xlocmes
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/ir/constants.h
참고: 포함 파일:                 C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/ir/scope.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/runtime/operator.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/overloaded.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/runtime/operator_options.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/schema_info.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/enum_type.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/interned_strings.h
참고: 포함 파일:                C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/core/aten_interned_strings.h
참고: 포함 파일:              C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/runtime/graph_executor.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/python/update_graph_executor_opt.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/runtime/argument_spec.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/runtime/interpreter.h
참고: 포함 파일:               C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/runtime/variable_tensor_list.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/api/include/torch/ordered_dict.h
참고: 포함 파일:           C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/api/compilation_unit.h
참고: 포함 파일:            C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/frontend/name_mangler.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/serialize/output-archive.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/samplers/stream.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/serialize.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/serialize/tensor.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/datasets/map.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/datasets/mnist.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/datasets/shared.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/datasets/tensor.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/transforms.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/transforms/base.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/transforms/collate.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/transforms/lambda.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/transforms/stack.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/data/transforms/tensor.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/enum.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/fft.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/jit.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/linalg.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/mps.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nested.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/cloneable.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/module.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/any_module_holder.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/any_value.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/detail/static.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/pimpl.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/api/include/torch/nn/pimpl-inl.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/utils.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Parallel.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Config.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/ParallelOpenMP.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/Parallel-inl.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/ParallelGuard.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/profiler.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/profiler_kineto.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/profiler/api.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/profiler/orchestration/observer.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/profiler/events.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/profiler/stubs/base.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\c10/util/strong_type.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/profiler/util.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/profiler_legacy.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/batchnorm.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/batchnorm.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/conv.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/conv.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/expanding_array.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/distance.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/distance.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/dropout.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/dropout.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/embedding.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/embedding.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/fold.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/fold.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/instancenorm.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/instancenorm.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/linear.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/loss.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/activation.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/activation.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/linear.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/loss.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/normalization.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/padding.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/PadNd.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/padding.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/pooling.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/utils.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/pooling.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/normalization.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/pixelshuffle.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/pixelshuffle.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/upsampling.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/upsampling.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/functional/vision.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/vision.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/init.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/common.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/any.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/functional.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/moduledict.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/modulelist.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/named_any.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/parameterdict.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/parameterlist.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/container/sequential.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/activation.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/linear.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/adaptive.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/adaptive.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/batchnorm.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/conv.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/distance.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/dropout.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/embedding.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/fold.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/instancenorm.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/loss.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/normalization.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/_functions.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/padding.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/pixelshuffle.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/pooling.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/rnn.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/rnn.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/utils/rnn.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/transformer.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/transformer.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/transformerlayer.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/transformercoder.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options/transformercoder.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/transformerlayer.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/modules/upsampling.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/options.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/utils.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/utils/clip_grad.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/nn/utils/convert_parameters.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/adagrad.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/optimizer.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/serialize.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/adam.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/adamw.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/lbfgs.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/rmsprop.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/sgd.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/schedulers/lr_scheduler.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/optim/schedulers/step_lr.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/sparse.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/special.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/version.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/xpu.h
참고: 포함 파일:  C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch\csrc\api\include\torch/python.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/Device.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/python_headers.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\Python.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\patchlevel.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pyconfig.h
참고: 포함 파일:       C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\io.h
참고: 포함 파일:        C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\corecrt_io.h
참고: 포함 파일:       C:\Program Files (x86)\Windows Kits\10\\include\10.0.22621.0\\shared\basetsd.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pymacconfig.h
참고: 포함 파일:      C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\assert.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pyport.h
참고: 포함 파일:       C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\inttypes.h
참고: 포함 파일:       C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\math.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\exports.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pymacro.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pymath.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pymem.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pymem.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pytypedefs.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pybuffer.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\object.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/object.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\objimpl.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/objimpl.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\typeslots.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pyhash.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pydebug.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\bytearrayobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/bytearrayobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\bytesobject.h
참고: 포함 파일:       C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\stdarg.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/bytesobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\unicodeobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/unicodeobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/code.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/initconfig.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pystate.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pystate.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pyerrors.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pyerrors.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\longobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/longobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/longintrepr.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\boolobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\floatobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/floatobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\complexobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/complexobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\rangeobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\memoryobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\tupleobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/tupleobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\listobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/listobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\dictobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/dictobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/odictobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\enumobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\setobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/setobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\methodobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/methodobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\moduleobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/funcobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/classobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\fileobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/fileobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pycapsule.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pyframe.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pyframe.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\traceback.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/traceback.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\sliceobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/cellobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\iterobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/genobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\descrobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/descrobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\genericaliasobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\warnings.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/warnings.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\weakrefobject.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/weakrefobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\structseq.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/picklebufobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pytime.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\codecs.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pythread.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pythread.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/context.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\modsupport.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/modsupport.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\compile.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/compile.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pythonrun.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pythonrun.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pylifecycle.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pylifecycle.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\ceval.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/ceval.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\sysmodule.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/sysmodule.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\osmodule.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\intrcheck.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\import.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/import.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\abstract.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/abstract.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\bltinmodule.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pyctype.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pystrtod.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\pystrcmp.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\fileutils.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/fileutils.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/pyfpe.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\tracemalloc.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\frameobject.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Include\cpython/frameobject.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/Dtype.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/DynamicTypes.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/Exceptions.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\ATen/detail/FunctionTraits.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11/pybind11.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail/class.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail\../attr.h
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail/common.h
참고: 포함 파일:        C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\forward_list
참고: 포함 파일:        C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\version
참고: 포함 파일:       C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\cast.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail/descr.h
참고: 포함 파일:        C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail/type_caster_base.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail\../pytypes.h
참고: 포함 파일:          C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\buffer_info.h
참고: 포함 파일:          C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\assert.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail\internals.h
참고: 포함 파일:         C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail\typeid.h
참고: 포함 파일:      C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail\../options.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\detail/init.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\gil.h
참고: 포함 파일:      C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cassert
참고: 포함 파일:       C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\assert.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\gil_safe_call_once.h
참고: 포함 파일:      C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\cassert
참고: 포함 파일:       C:\Program Files (x86)\Windows Kits\10\include\10.0.22621.0\ucrt\assert.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11\typing.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/runtime/jit_exception.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/cpp_stacktraces.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/pybind.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\pybind11/stl.h
참고: 포함 파일:      C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\include\valarray
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/Generator.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/MemoryFormat.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/Stream.h
참고: 포함 파일:     C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/tensor_memoryformats.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/autograd/python_variable.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/pythoncapi_compat.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/python_numbers.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/jit/frontend/tracer.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/object_ptr.h
참고: 포함 파일:    C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/tensor_numpy.h
참고: 포함 파일:   C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\include\torch/csrc/utils/python_tuples.h
참고: 포함 파일: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\cuda_fp16.h
참고: 포함 파일:  C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\vector_types.h
참고: 포함 파일:   C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\crt/host_defines.h
참고: 포함 파일:  C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\vector_functions.h
참고: 포함 파일:   C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\cuda_runtime_api.h
참고: 포함 파일:    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\crt/host_defines.h
참고: 포함 파일:    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\builtin_types.h
참고: 포함 파일:     C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\device_types.h
참고: 포함 파일:      C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\crt/host_defines.h
참고: 포함 파일:     C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\driver_types.h
참고: 포함 파일:      C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\crt/host_defines.h
참고: 포함 파일:      C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\vector_types.h
참고: 포함 파일:     C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\surface_types.h
참고: 포함 파일:      C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\driver_types.h
참고: 포함 파일:     C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\texture_types.h
참고: 포함 파일:      C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\driver_types.h
참고: 포함 파일:     C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\vector_types.h
참고: 포함 파일:    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\cuda_device_runtime_api.h
참고: 포함 파일:   C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\vector_functions.hpp
참고: 포함 파일:    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\cuda_runtime_api.h
참고: 포함 파일:  C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\nv/target
참고: 포함 파일:   C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\nv/detail/__target_macros
참고: 포함 파일:    C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\nv/detail/__preprocessor
참고: 포함 파일:  C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\include\cuda_fp16.hpp
[2/2] "C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.42.34433\bin\Hostx64\x64/link.exe" _wrapper.o flash_attention.cuda.o /nologo /DLL c10.lib c10_cuda.lib torch_cpu.lib torch_cuda.lib -INCLUDE:?warp_size@cuda@at@@YAHXZ torch.lib /LIBPATH:C:\Users\PC\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\lib torch_python.lib /LIBPATH:C:\Users\PC\AppData\Local\Programs\Python\Python311\libs "/LIBPATH:C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\lib\x64" cudart.lib /out:flash_attn_ext.pyd
   flash_attn_ext.lib 라이브러리 및 flash_attn_ext.exp 개체를 생성하고 있습니다.
Compile done.

============================================================
Correctness
============================================================
  bh=4 n=128 d=128
    flash: max_err=0.000977  mean=0.000057  PASS
    naive: max_err=0.000977  mean=0.000057  PASS
  bh=4 n=256 d=128
    flash: max_err=0.000610  mean=0.000043  PASS
    naive: max_err=0.000610  mean=0.000043  PASS
  bh=4 n=512 d=128
    flash: max_err=0.000488  mean=0.000032  PASS
    naive: max_err=0.000488  mean=0.000032  PASS
  bh=4 n=1024 d=128
    flash: max_err=0.000488  mean=0.000023  PASS
    naive: max_err=0.000488  mean=0.000023  PASS

ALL PASSED

============================================================
Benchmark (bh=32, d=128)
============================================================
  n=512    naive=25.81      flash=6200.94    sdpa=0.44       flash/naive=0.00x
  n=1024   naive=263.50     flash=19582.74   sdpa=1.47       flash/naive=0.01x
  n=2048   naive=1139.11    flash=68865.85   sdpa=5.13       flash/naive=0.02x

============================================================
Theoretical DRAM traffic (bh=32, d=128)
============================================================

n        standard (MB)    tiled (MB)       reduction   
----------------------------------------------------
512      80.0             72.0             10.0        %
1024     288.0            272.0            5.6         %
2048     1088.0           1056.0           2.9         %

Next: profile with ncu --set full --kernel-name flash_attn_fwd ./bench
==PROF== Disconnected from process 26448
"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,742,192,744.56",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,309,911,287.29",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","2,752,752",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","20.92",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.63",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","1,191,712",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","89.07",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.37",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","646,467.12",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","2.05",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","OPT","This kernel grid is too small to fill the available resources on this device, resulting in only 0.2 full waves across all SMs. Look at Launch Statistics for more details.","",""
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 0% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","8,781,824",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","2,000",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.03",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","0.74",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","0.74",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","99.61"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,551,220,429.10",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","20.92",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","2.05",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","8.33",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","45.79",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","2.05",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 666176 shared load requests.This results in 10297344 bank conflicts,  which represent 93.35% of the overall 11030592 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","83.15"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.4 - way bank conflict across all 280672 shared store requests.This results in 8253440 bank conflicts,  which represent 96.71% of the overall 8534112 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","86.14"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","79.08"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.67",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.67",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.68",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 42.4% of the total average of 31.7 cycles between issuing two instructions.","global","42.38"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.0 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 41.0% of the total average of 31.7 cycles between issuing two instructions.","global","40.99"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","20,422.82",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","2,777,504",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","20,426.59",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","2,778,016",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Block Size","","128",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Grid Size","","8",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Threads","thread","1,024",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Launch Statistics","Waves Per SM","","0.24",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","LaunchStats","","","","LaunchConfiguration","OPT","The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 34 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.","global","76.47"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","79.08"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","169,492",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","41,672,704",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","646,467.12",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","93,593,468",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","269,646",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","36,894,000",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","646,467.12",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","93,593,468",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","646,931.57",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","374,373,872",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 76.50% above the average, while the minimum instance value is 100.00% below the average.","global","17.96"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 76.50% above the average, while the minimum instance value is 100.00% below the average.","global","17.98"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 76.50% above the average, while the minimum instance value is 100.00% below the average.","global","17.96"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L2 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 44.78% above the average, while the minimum instance value is 9.37% below the average.","global","5.236"
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.03",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Source Counters","Branch Instructions","inst","76,672",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"0","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(2, 4, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 18550784 excessive wavefronts (95% of the total 19564704 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","22.27"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,742,181,882.32",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,309,961,231.63",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","5,448,334",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","42.26",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.61",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","2,358,624",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","89.92",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.31",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2,560,517.59",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","4.12",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","OPT","This kernel grid is too small to fill the available resources on this device, resulting in only 0.5 full waves across all SMs. Look at Launch Statistics for more details.","",""
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 0% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","15,990,784",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","1,000",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.06",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","1.47",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","1.47",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","99.22"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,503,941,281.02",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","42.26",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","4.12",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","5",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","19.20",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","4.12",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 2656512 shared load requests.This results in 41189376 bank conflicts,  which represent 93.37% of the overall 44114176 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","83.96"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.6 - way bank conflict across all 1114432 shared store requests.This results in 33013763 bank conflicts,  which represent 96.73% of the overall 34128195 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","86.99"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.13",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.87",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 32.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","57.74"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.99",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.99",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.72",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.7 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 42.8% of the total average of 32.0 cycles between issuing two instructions.","global","42.76"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.3 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 41.4% of the total average of 32.0 cycles between issuing two instructions.","global","41.43"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","80,045.65",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","10,886,208",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","80,049.88",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","10,886,784",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Block Size","","128",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Grid Size","","16",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Threads","thread","2,048",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Launch Statistics","Waves Per SM","","0.47",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","LaunchStats","","","","LaunchConfiguration","OPT","The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 34 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.","global","52.94"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","57.74"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","331,972",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","82,478,080",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","2,560,517.59",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","185,243,232",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","364,898.12",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","73,021,728",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","2,560,517.59",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","185,243,232",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","2,560,860.35",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","740,972,928",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 52.99% above the average, while the minimum instance value is 100.00% below the average.","global","24.9"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 52.99% above the average, while the minimum instance value is 100.00% below the average.","global","24.91"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 52.99% above the average, while the minimum instance value is 100.00% below the average.","global","24.9"
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.03",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Source Counters","Branch Instructions","inst","277,632",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"1","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(4, 4, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 74203136 excessive wavefronts (95% of the total 78242368 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","44.57"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,249,189,137.32",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,179,575,429.95",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","10,902,635",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","84.46",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.36",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","5,002,080",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","90.48",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","10,177,204.74",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.20",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","12,582,912",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","2,000",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.12",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.91",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.12",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.91",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.44"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,584,838,307.26",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","84.46",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.20",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","53.90",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.20",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 10609664 shared load requests.This results in 164757504 bank conflicts,  which represent 93.38% of the overall 176440320 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","84.49"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 4441216 shared store requests.This results in 132055044 bank conflicts,  which represent 96.75% of the overall 136496260 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","87.54"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.11",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.89",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 32.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","15.54"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","32.12",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.12",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.0% of the total average of 32.1 cycles between issuing two instructions.","global","15.54"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 41.7% of the total average of 32.1 cycles between issuing two instructions.","global","15.54"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","316,891.76",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","43,097,280",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","316,909.18",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","43,099,648",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Block Size","","128",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Grid Size","","32",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Threads","thread","4,096",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Launch Statistics","Waves Per SM","","0.94",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","LaunchStats","","","","LaunchConfiguration","OPT","The grid for this launch is configured to execute only 32 blocks, which is less than the GPU's 34 multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel concurrently with other workloads, consider reducing the block size to have at least one block per multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.","global","5.882"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","15.54"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","560,364",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","165,052,416",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","10,177,204.74",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","370,682,598",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","705,522.12",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","146,125,632",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","10,177,204.74",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","370,682,598",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","10,179,928.97",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","1,482,730,392",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.95% above the average, while the minimum instance value is 100.00% below the average.","global","5.555"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.96% above the average, while the minimum instance value is 100.00% below the average.","global","5.564"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.95% above the average, while the minimum instance value is 100.00% below the average.","global","5.555"
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Source Counters","Branch Instructions","inst","1,052,480",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"2","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 4, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 296812544 excessive wavefronts (95% of the total 312936576 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.54"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,068,572,252.37",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,131,814,573.25",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","43,535,338",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","84.60",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.72",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","20,421,088",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.29",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.87",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","40,346,107.68",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.20",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","16,318,464",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.90",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.90",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.44"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,435,045,184.66",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","84.60",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.20",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","22.57",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.20",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 42405888 shared load requests.This results in 659030016 bank conflicts,  which represent 93.38% of the overall 705728512 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.25"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 17731840 shared store requests.This results in 528220161 bank conflicts,  which represent 96.75% of the overall 545952003 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.32"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.13",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.87",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 32.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","15.4"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.98",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.98",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.4% of the total average of 32.0 cycles between issuing two instructions.","global","15.4"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.1% of the total average of 32.0 cycles between issuing two instructions.","global","15.4"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","1,260,982.59",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","171,493,632",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","1,261,038.29",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","171,501,208",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Block Size","","128",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Grid Size","","64",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Threads","thread","8,192",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Launch Statistics","Waves Per SM","","1.88",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","LaunchStats","","","","LaunchConfiguration","OPT","If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have at least two blocks per multiprocessor (compared to the currently executed 1.9 blocks) This way, blocks that aren't waiting for __syncthreads() can keep the hardware busy.","",""
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","LaunchStats","","","","LaunchConfiguration","OPT","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 30 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, this partial wave may account for up to 50.0% of the total runtime of this kernel. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations.","global","50"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","15.4"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","2,830,264",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","659,076,096",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","40,346,107.68",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","1,480,158,838",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","2,416,058.19",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","583,492,768",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","40,346,107.68",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","1,480,158,838",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","40,320,578.51",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","5,920,635,352",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 6.45% above the average, while the minimum instance value is 46.54% below the average.","global","5.976"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 6.50% above the average, while the minimum instance value is 46.50% below the average.","global","6.022"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 6.45% above the average, while the minimum instance value is 46.54% below the average.","global","5.976"
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Source Counters","Branch Instructions","inst","4,093,568",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"3","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 4, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 1187250176 excessive wavefronts (95% of the total 1251680512 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","87.91"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,620,547,391.27",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,277,801,993.74",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,440,161",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.22",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.72",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","37,509,696",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.65",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.50",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,382,223.68",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.37",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,660,800",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,753,465,770.56",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.22",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.37",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","39.56",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.37",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440343 bank conflicts,  which represent 96.75% of the overall 1091970072 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.66"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.78"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.70",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.78"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.78"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,130.35",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,728",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,173",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,783,528",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.78"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,571,908",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,293,416,448",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,382,223.68",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,904,949,958",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,585,025.38",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,145,121,320",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,382,223.68",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,904,949,958",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,376,723.49",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,619,799,832",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.397"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.396"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.397"
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,660",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"4","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.23"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,742,252,311.06",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,309,989,294.29",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,264,574",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.40",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.79",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","36,911,136",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.66",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.49",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,374,072",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.39",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,333,120",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","5,011,241,702.23",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.40",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.39",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","39.57",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.39",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.59"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440343 bank conflicts,  which represent 96.75% of the overall 1091970071 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.67"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.6"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.70",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.6"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.6"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,131.53",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,888",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,172.35",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,783,440",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.6"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,780,332",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,290,745,856",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,374,072",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,898,988,138",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,739,221.81",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,142,763,328",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,374,072",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,898,988,138",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,386,300.82",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,595,952,552",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.402"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.402"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.402"
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,736",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"5","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.41"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,624,185,586.77",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,278,754,203.48",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,430,142",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.23",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.68",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","37,489,568",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.65",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.49",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,377,058.47",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.37",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,660,800",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,645,606,799.20",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.23",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.37",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","35.49",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.37",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440340 bank conflicts,  which represent 96.75% of the overall 1091970068 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.67"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.77"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.77"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.77"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,131.62",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,900",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,172.41",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,783,448",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.77"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,442,556",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,293,267,968",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,377,058.47",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,904,605,322",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,646,619.81",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,144,988,360",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,377,058.47",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,904,605,322",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,387,204.50",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,618,421,288",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.399"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.401"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.399"
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,328",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"6","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.24"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,742,249,810.81",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,309,988,885.32",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,275,245",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.39",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.41",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","36,915,744",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.64",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,384,813.79",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.39",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,333,120",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,955,947,251.12",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.39",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.39",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","32.99",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.39",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440334 bank conflicts,  which represent 96.75% of the overall 1091970062 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.66"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.61"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.70",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.61"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.61"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,132.68",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,044",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,145.88",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,779,840",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.61"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,563,648",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,290,906,624",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,384,813.79",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,899,349,676",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,032,279.88",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,142,907,776",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,384,813.79",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,899,349,676",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,372,865.47",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,597,398,704",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.402"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.408"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.402"
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,328",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"7","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.41"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,742,242,731.23",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,309,985,980.00",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,268,870",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.39",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.53",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","36,912,992",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.65",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.40",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,377,751.41",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.39",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,333,120",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,289,081,091.02",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.39",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.39",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","31.29",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.39",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440337 bank conflicts,  which represent 96.75% of the overall 1091970065 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.67"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.61"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.61"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.61"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,132.85",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,068",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,169.88",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,783,104",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.61"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,947,588",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,290,809,344",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,377,751.41",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,899,130,272",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","4,903,990",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,142,822,912",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,377,751.41",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,899,130,272",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,372,829.40",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,596,521,088",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.403"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.75% above the average, while the minimum instance value is 6.96% below the average.","global","5.419"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.403"
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,328",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"8","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.41"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","7,945,111,715.71",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,099,258,598.13",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","86,642,026",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.03",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.81",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","41,271,904",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.01",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.44",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,948,102.09",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.26",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,119,552",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.93",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.93",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.43"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,591,064,759.21",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.03",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.26",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","110.39",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.26",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","84.98"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440338 bank conflicts,  which represent 96.75% of the overall 1091970068 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.04"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","14.97"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.70",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","14.97"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.97"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,130.35",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,728",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,215.65",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,789,329",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.32",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.97"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,921,312",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,311,639,552",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,948,102.09",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,945,778,174",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,595,345.31",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,161,237,744",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,948,102.09",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,945,778,174",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,374,955.07",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,783,112,696",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.84% above the average, while the minimum instance value is 7.08% below the average.","global","5.452"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.75% above the average, while the minimum instance value is 6.96% below the average.","global","5.332"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.84% above the average, while the minimum instance value is 7.08% below the average.","global","5.452"
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,328",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"9","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.62"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,034,098,132.54",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,122,800,601.07",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,919,620",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.74",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","2.18",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","40,474,240",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.63",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.78",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,400,858.21",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.32",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,223,616",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.95",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.95",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","5,616,315,365.03",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.74",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.32",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","74.10",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.32",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.56"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440339 bank conflicts,  which represent 96.75% of the overall 1091970069 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.64"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","14.26"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.74",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.75",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.5% of the total average of 31.7 cycles between issuing two instructions.","global","14.26"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.26"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,134.10",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,237",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,184.18",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,785,048",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.26"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","7,103,628",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,300,696,064",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,400,858.21",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,921,239,100",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","6,271,994.06",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,151,557,448",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,400,858.21",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,921,239,100",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,452,239.10",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,684,956,400",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.71% above the average, while the minimum instance value is 7.00% below the average.","global","5.343"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.72% above the average, while the minimum instance value is 6.97% below the average.","global","5.351"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.71% above the average, while the minimum instance value is 7.00% below the average.","global","5.343"
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,790",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"10","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.76"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,446,254,207.56",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,231,741,041.95",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,587,738",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.07",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.77",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","38,350,016",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.64",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.48",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,383,946.56",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.36",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,185,088",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,787,601,861.76",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.07",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.36",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","80.36",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.36",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440336 bank conflicts,  which represent 96.75% of the overall 1091970067 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.66"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.93"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.93"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.93"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,133.24",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,120",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,192.97",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,786,244",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.93"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,737,644",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,295,655,936",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,383,946.56",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,909,969,384",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,765,947.56",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,147,104,344",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,383,946.56",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,909,969,384",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,383,772.19",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,639,877,536",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.384"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.72% above the average, while the minimum instance value is 6.97% below the average.","global","5.372"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.384"
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,640",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"11","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.08"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,291,410,036.69",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,190,815,124.84",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,699,249",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.96",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.41",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","39,117,280",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.65",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,377,550.06",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.35",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,922,944",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,734,604,042.00",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.96",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.35",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","44.09",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.35",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440338 bank conflicts,  which represent 96.75% of the overall 1091970070 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.67"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","14.04"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","14.04"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.04"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,132.74",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,052",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,188.94",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,785,696",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.04"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,565,236",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,297,349,632",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,377,550.06",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,913,758,024",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,013,044",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,148,600,864",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,377,550.06",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,913,758,024",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,379,611.54",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,655,032,096",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.379"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.381"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.379"
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,734",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"12","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.96"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,444,680,607.91",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,231,292,103.11",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,596,456",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.06",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.44",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","38,361,376",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.65",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,376,452.85",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.36",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,857,408",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,900,790,211.49",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.06",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.36",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","45.34",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.36",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440338 bank conflicts,  which represent 96.75% of the overall 1091970066 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.67"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.94"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.94"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.94"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,132.71",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,048",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,189.49",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,785,770",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.94"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,676,240",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,295,798,272",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,376,452.85",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,910,247,834",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,251,713.12",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,147,221,888",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,376,452.85",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,910,247,834",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,375,339.30",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,640,991,336",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.388"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.75% above the average, while the minimum instance value is 6.96% below the average.","global","5.398"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.388"
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,908",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"13","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.06"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,445,888,833.25",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,231,640,916.24",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,566,937",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.09",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.49",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","38,342,400",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.66",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,372,020.97",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.36",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,119,552",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,021,962,944.42",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.09",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.36",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","49.65",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.36",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.59"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440339 bank conflicts,  which represent 96.75% of the overall 1091970069 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.68"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.91"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.91"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.91"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,131.84",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,930",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,184.38",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,785,076",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.91"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,819,116",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,295,342,592",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,372,020.97",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,909,260,940",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,462,696.88",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,146,825,584",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,372,020.97",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,909,260,940",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,366,329.49",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,637,043,760",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.382"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.383"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.382"
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,654",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"14","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.09"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,027,608,360.92",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,121,087,191.85",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,870,735",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.79",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.45",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","40,483,968",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.65",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.43",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,380,527.79",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.33",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,185,088",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.95",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.95",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,713,599,615.53",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.79",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.33",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","98.89",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","223",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","3,608",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","134.74",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.33",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440340 bank conflicts,  which represent 96.75% of the overall 1091970070 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.67"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","14.21"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","14.21"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.21"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,132.47",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,016",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,186.12",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,785,312",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.21"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,698,164",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,299,957,760",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,380,527.79",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,919,582,654",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,220,834.50",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,150,902,648",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,380,527.79",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,919,582,654",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,379,027.62",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,678,330,616",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.365"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.374"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.365"
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,696",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"15","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.78"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,241,610,934.47",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,177,587,359.45",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,804,352",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.86",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.52",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","39,402,720",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.64",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.42",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,384,154.12",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.34",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,250,624",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.95",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.95",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,010,297,766.25",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.86",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.34",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","100",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","3.02",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","528",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","120.83",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.34",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440330 bank conflicts,  which represent 96.75% of the overall 1091970058 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.66"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","14.14"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","14.14"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.14"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,132.91",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,076",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,193.76",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,786,352",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.37",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.02",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.14"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,938,020",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,298,967,552",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,384,154.12",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,917,301,712",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,190,932.56",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,150,017,624",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,384,154.12",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,917,301,712",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,414,311.25",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,669,206,848",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.378"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.375"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.378"
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,678",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"16","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.86"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,561,099,589.28",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,262,080,051.52",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,443,642",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.22",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.27",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","37,771,776",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.64",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.43",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,384,400.24",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.37",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,333,120",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,474,224,987.46",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.22",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.37",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","32.06",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.37",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440341 bank conflicts,  which represent 96.75% of the overall 1091970069 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.66"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.78"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.70",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.78"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.78"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,130.35",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,728",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,145.88",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,779,840",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.78"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,100,864",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,293,471,744",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,384,400.24",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,905,057,582",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","4,895,452.56",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,145,170,560",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,384,400.24",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,905,057,582",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,374,559.74",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,620,230,328",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.391"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.398"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.391"
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,460",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"17","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.23"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","6,490,683,712.49",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","1,714,869,651.19",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","88,273,831",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","83.46",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","2.61",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","51,472,864",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","90.78",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.84",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","81,152,366.59",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.10",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","11,272,192",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.12",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.11",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.87",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.12",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.87",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.46"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","5,413,322,872.42",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","83.46",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.10",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","168",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","30.48",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.10",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 5376.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","2.085"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","84.77"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440336 bank conflicts,  which represent 96.75% of the overall 1091970064 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","87.82"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.14",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.86",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","16.54"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.75",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.76",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.5% of the total average of 31.8 cycles between issuing two instructions.","global","16.54"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.8 cycles between issuing two instructions.","global","16.54"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,140.53",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,779,112",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,314.69",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,802,798",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.30",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.98",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","16.54"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","8,707,476",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,336,376,320",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","81,152,366.59",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","3,001,167,624",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,943,638.19",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,183,115,560",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","81,152,366.59",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","3,001,167,624",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,862,058.62",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","12,004,670,496",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.76% above the average, while the minimum instance value is 7.11% below the average.","global","5.297"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.79% above the average, while the minimum instance value is 6.89% below the average.","global","5.302"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.76% above the average, while the minimum instance value is 7.11% below the average.","global","5.297"
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,420,251",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"18","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","87.2"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","6,532,109,678.17",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","1,725,915,386.96",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","88,213,175",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","83.51",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","2.31",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","51,109,824",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","90.88",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.62",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","81,063,160.06",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.11",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","11,993,088",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.11",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.87",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.87",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.46"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,836,017,435.71",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","83.51",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.11",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","88",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","86.34",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.11",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 2816.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.905"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","84.86"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440332 bank conflicts,  which represent 96.75% of the overall 1091970061 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","87.92"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","16.49"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","16.49"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","16.49"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,133.26",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,124",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,250.24",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,794,032",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.28",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.97",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","16.49"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","7,724,000",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,335,419,904",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","81,063,160.06",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,999,186,592",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","6,233,270.75",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,182,295,776",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","81,063,160.06",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,999,186,592",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,368,511.76",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,996,746,368",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.69% above the average, while the minimum instance value is 7.09% below the average.","global","5.229"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.224"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.69% above the average, while the minimum instance value is 7.09% below the average.","global","5.229"
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,652",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"19","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","87.16"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,427,751,420.86",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,226,807,466.87",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,584,209",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.08",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.45",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","38,433,088",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.65",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.40",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,380,419.32",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.36",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,922,944",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,904,851,985.87",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.08",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.36",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.77",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","49.00",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.36",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440339 bank conflicts,  which represent 96.75% of the overall 1091970067 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.67"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.92"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.92"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.92"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,130.35",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,728",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,227.27",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,790,909",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.92"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,689,860",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,295,618,048",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,380,419.32",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,909,828,148",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","4,982,699.75",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,147,059,208",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,380,419.32",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,909,828,148",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,379,142.09",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,639,312,592",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.96% below the average.","global","5.388"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.392"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.96% below the average.","global","5.388"
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,619",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"20","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.08"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,742,242,729.10",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,309,996,063.93",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,261,701",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.40",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.45",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","36,909,888",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.66",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.42",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,374,373.38",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.39",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,333,120",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,046,424,849.62",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.40",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.39",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","32.82",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.39",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.446"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.59"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440337 bank conflicts,  which represent 96.75% of the overall 1091970066 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.67"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.6"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.70",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","13.6"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","13.6"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,130.62",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,764",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,145.88",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,779,840",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.6"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,667,284",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,290,700,800",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,374,373.38",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,898,897,680",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","4,932,799.56",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,142,728,224",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,374,373.38",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,898,897,680",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,372,865.45",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,595,590,720",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.4"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.406"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.4"
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,944",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"21","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.41"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","7,826,845,601.48",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,067,952,792.69",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","86,121,398",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.54",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.41",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","41,644,960",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.57",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.45",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,451,578.35",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.31",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,551,296",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.94",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.94",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,539,460,813.51",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.54",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.31",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","64.17",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.31",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.5"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440331 bank conflicts,  which represent 96.75% of the overall 1091970060 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.59"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","14.46"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","14.46"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.46"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,133.69",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,182",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,240.56",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,792,716",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.46"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,606,272",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,303,794,688",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,451,578.35",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,928,078,204",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,482,470.38",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,154,273,896",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,451,578.35",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,928,078,204",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,386,886",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,712,312,816",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.361"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.356"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.97% below the average.","global","5.361"
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,684",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"22","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.6"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","7,716,362,676.71",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,038,856,269.97",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","87,023,726",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","84.65",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","2.24",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","42,682,112",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.08",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","1.14",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,882,484.26",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.22",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,878,976",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.91",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.91",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.44"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","5,524,974,959.06",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","84.65",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.22",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","66.71",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.22",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.05"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440340 bank conflicts,  which represent 96.75% of the overall 1091970070 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.12"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","15.35"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.72",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.72",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.5% of the total average of 31.7 cycles between issuing two instructions.","global","15.35"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","15.35"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,134.53",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,296",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,265.50",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,796,108",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","15.35"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","7,369,300",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,317,402,624",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,882,484.26",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,958,774,096",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,938,576.50",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,166,353,384",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,882,484.26",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,958,774,096",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,394,035.84",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,835,096,384",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.79% above the average, while the minimum instance value is 7.05% below the average.","global","5.383"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.75% above the average, while the minimum instance value is 6.95% below the average.","global","5.313"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.79% above the average, while the minimum instance value is 7.05% below the average.","global","5.383"
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,420,174",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"23","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.16"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","7,938,486,980.67",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,097,446,822.13",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","86,043,617",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.62",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.61",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","41,022,080",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.65",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.64",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,382,864.94",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.31",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,660,800",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.95",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.95",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,081,585,721.64",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.62",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.31",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","78.40",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.31",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.58"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440334 bank conflicts,  which represent 96.75% of the overall 1091970065 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.66"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","14.38"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","14.38"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.38"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,135.96",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,491",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,172.65",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,783,480",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.36",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.38"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,232,348",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,302,612,992",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,382,864.94",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,925,421,438",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","6,368,959.25",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,153,231,584",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,382,864.94",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,925,421,438",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,394,725.07",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,701,685,752",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.75% above the average, while the minimum instance value is 6.97% below the average.","global","5.368"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.76% above the average, while the minimum instance value is 6.95% below the average.","global","5.386"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.75% above the average, while the minimum instance value is 6.97% below the average.","global","5.368"
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,420,267",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"24","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.61"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,075,858,085.08",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,133,784,993.77",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","86,052,624",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.61",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.54",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","40,327,936",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.46",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.43",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,545,497.24",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.31",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,119,552",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","8,000",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.95",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.95",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,980,971,999.16",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.61",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.31",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","103.40",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.31",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.4"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440334 bank conflicts,  which represent 96.75% of the overall 1091970062 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.48"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","14.39"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.75",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.75",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.5% of the total average of 31.8 cycles between issuing two instructions.","global","14.39"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.8 cycles between issuing two instructions.","global","14.39"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,134.37",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,274",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,236.62",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,792,180",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.39"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,017,012",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,302,730,752",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,545,497.24",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,925,743,688",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","6,091,535.38",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,153,344,144",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,545,497.24",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,925,743,688",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,509,600.54",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,702,974,752",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.71% above the average, while the minimum instance value is 6.98% below the average.","global","5.342"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.70% above the average, while the minimum instance value is 6.99% below the average.","global","5.333"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.71% above the average, while the minimum instance value is 6.98% below the average.","global","5.342"
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,693",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"25","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.78"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","7,689,103,449.93",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,031,615,947.39",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","86,564,687",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.10",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.97",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","42,608,128",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.30",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.90",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,686,103.15",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.26",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,289,152",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.93",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.93",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.43"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,853,323,760.20",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.10",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.26",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","25.08",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.26",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.26"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440349 bank conflicts,  which represent 96.75% of the overall 1091970077 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.33"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","14.9"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.74",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.74",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.5% of the total average of 31.7 cycles between issuing two instructions.","global","14.9"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.9"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,133.90",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,210",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,222.41",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,790,248",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.9"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","6,462,220",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,310,473,216",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,686,103.15",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,943,157,474",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,554,063.94",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,160,205,680",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,686,103.15",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,943,157,474",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,556,288.02",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,772,629,896",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.92% below the average.","global","5.354"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.72% above the average, while the minimum instance value is 6.97% below the average.","global","5.322"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.74% above the average, while the minimum instance value is 6.92% below the average.","global","5.354"
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,420,121",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"26","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.41"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,376,336,077.88",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,213,257,634.31",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","85,682,924",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.98",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.43",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","38,713,312",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.56",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.40",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,460,802.26",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.35",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,485,760",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,831,511,393.29",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.98",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.35",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.78",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","112.59",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.35",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.49"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440342 bank conflicts,  which represent 96.75% of the overall 1091970070 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.58"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","14.02"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.74",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.74",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.5% of the total average of 31.7 cycles between issuing two instructions.","global","14.02"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.02"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,136.12",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,778,512",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,222.12",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,790,208",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.02"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","4,635,328",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,297,102,848",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,460,802.26",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,913,207,242",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,862,422.44",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,148,383,112",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,460,802.26",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,913,207,242",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,381,266.12",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,652,828,968",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.379"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.72% above the average, while the minimum instance value is 6.97% below the average.","global","5.369"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.97% below the average.","global","5.379"
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,847",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"27","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.07"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,094,189,680.06",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,138,693,844.55",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","86,291,675",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.37",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.55",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","40,347,520",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.26",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.44",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","80,726,243.91",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.29",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,289,152",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","16,000",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.94",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.94",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.43"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,005,723,077.90",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.37",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.29",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","2.77",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","51.27",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.29",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 84877312 shared load requests.This results in 1318060032 bank conflicts,  which represent 93.38% of the overall 1411522560 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.21"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.7 - way bank conflict across all 35529728 shared store requests.This results in 1056440341 bank conflicts,  which represent 96.75% of the overall 1091970070 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.29"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","14.63"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.71",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.71",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.8 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.7 cycles between issuing two instructions.","global","14.63"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.4 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.7 cycles between issuing two instructions.","global","14.63"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","2,535,131.71",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","344,777,912",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","2,535,221.56",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","344,790,132",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Grid Size","","256",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Threads","thread","32,768",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","7.53",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.63"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","5,050,656",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","1,306,321,920",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","80,726,243.91",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","2,933,895,542",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","5,797,674.12",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","1,156,542,024",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","80,726,243.91",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","2,933,895,542",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","80,386,909.81",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","11,735,582,168",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.76% above the average, while the minimum instance value is 6.90% below the average.","global","5.385"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Additionally, other SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 6.98% below the average.","global","5.336"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Additionally, other L1 Slices have a much lower number of active cycles than the average number of active cycles. Maximum instance value is 5.76% above the average, while the minimum instance value is 6.90% below the average.","global","5.385"
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","8,419,752",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"28","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(8, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 2374500352 excessive wavefronts (95% of the total 2503492608 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.73"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,122,021,895.45",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,146,033,991.85",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","340,416,486",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.56",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.48",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","158,624,384",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.31",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.54",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","319,189,430.12",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.39",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,529,728",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,855,146,608.48",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.56",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.39",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","93.20",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.39",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.234"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.2"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761319 bank conflicts,  which represent 96.75% of the overall 4367616044 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.31"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.13",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.87",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 32.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.44"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.67",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.67",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.8% of the total average of 31.7 cycles between issuing two instructions.","global","13.44"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.7 cycles between issuing two instructions.","global","13.44"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,876.75",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,238",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,209.65",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,996,512",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.32",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.44"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","19,110,008",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,153,402,880",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","319,189,430.12",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,574,060,856",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,849,318.12",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,562,509,680",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","319,189,430.12",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,574,060,856",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","322,721,448.99",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,296,243,424",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.65% above the average, while the minimum instance value is 0.57% below the average.","global","5.298"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.89% above the average, while the minimum instance value is 0.41% below the average.","global","5.585"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.65% above the average, while the minimum instance value is 0.57% below the average.","global","5.298"
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,374",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"29","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.94"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,137,296,415.45",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,150,064,312.86",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","339,498,633",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.79",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.48",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","157,900,000",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.58",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.56",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","318,274,615.82",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.41",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,988,480",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.4"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,855,669,664.34",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.79",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.41",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","45.91",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.41",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.45"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761329 bank conflicts,  which represent 96.75% of the overall 4367616059 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.57"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.21"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.54",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.54",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.0% of the total average of 31.5 cycles between issuing two instructions.","global","13.21"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.7% of the total average of 31.5 cycles between issuing two instructions.","global","13.21"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,877.75",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,374",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,215.71",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,997,337",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.38",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.02",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.21"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","19,025,320",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,139,516,416",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","318,274,615.82",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,542,843,348",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,487,166.94",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,550,208,384",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","318,274,615.82",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,542,843,348",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","320,310,639.18",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,171,373,392",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.61% above the average, while the minimum instance value is 0.67% below the average.","global","5.264"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.62% above the average, while the minimum instance value is 0.57% below the average.","global","5.3"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.61% above the average, while the minimum instance value is 0.67% below the average.","global","5.264"
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,467",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"30","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.92"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","7,922,137,123.27",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,093,145,388.87",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","343,898,350",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.68",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.72",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","164,292,928",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.72",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.77",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","321,256,396.76",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.31",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,791,872",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","64,000",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.93",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.93",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,369,273,691.44",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.68",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.31",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","45.31",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.31",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.65"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761322 bank conflicts,  which represent 96.75% of the overall 4367616048 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.74"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.14",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.86",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","14.32"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.60",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.60",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","14.32"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","14.32"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,874.60",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,946",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,144.46",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,987,647",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.32"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","22,432,524",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,206,204,416",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","321,256,396.76",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,692,255,206",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,859,558.12",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,609,194,872",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","321,256,396.76",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,692,255,206",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","321,691,953.16",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,769,020,824",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.82% above the average, while the minimum instance value is 0.52% below the average.","global","5.434"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.79% above the average, while the minimum instance value is 0.46% below the average.","global","5.416"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.82% above the average, while the minimum instance value is 0.52% below the average.","global","5.434"
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,750,105",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"31","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.61"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,065,867,514.00",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,131,131,032.87",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","343,274,402",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.84",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.60",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","161,071,936",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.63",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.57",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","321,558,382.41",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.32",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,185,088",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.94",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.94",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,120,109,712.97",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.84",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.32",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.46",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","62.52",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.32",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.57"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761329 bank conflicts,  which represent 96.75% of the overall 4367616052 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.65"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","14.16"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.60",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.60",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","14.16"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","14.16"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,871.10",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,470",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,159.25",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,989,658",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.25",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.96",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.16"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","20,738,564",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,196,739,584",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","321,558,382.41",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,671,052,238",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,673,532.62",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,600,815,896",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","321,558,382.41",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,671,052,238",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","318,524,496.43",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,684,208,952",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.56% below the average.","global","5.304"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.64% above the average, while the minimum instance value is 0.63% below the average.","global","5.229"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.56% below the average.","global","5.304"
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,837",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"32","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.85"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,084,138,472.82",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,135,953,059.78",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","338,629,432",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","87.01",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.52",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","158,534,848",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.79",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.56",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","317,541,643.71",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.43",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,551,296",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","64,000",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.98",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.98",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.4"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,934,901,479.83",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","87.01",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.43",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","43.86",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.43",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.341"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.65"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761304 bank conflicts,  which represent 96.75% of the overall 4367616025 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.78"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.01",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.01 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","12.99"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.68",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.68",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.8% of the total average of 31.7 cycles between issuing two instructions.","global","12.99"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.7 cycles between issuing two instructions.","global","12.99"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,878.80",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,517",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,062.47",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,976,496",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","12.99"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","19,494,344",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,126,470,656",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","317,541,643.71",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,513,200,598",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,980,986.25",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,538,594,616",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","317,541,643.71",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,513,200,598",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","317,903,048.39",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,052,802,392",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.52% above the average, while the minimum instance value is 0.72% below the average.","global","5.18"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.58% below the average.","global","5.316"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.52% above the average, while the minimum instance value is 0.72% below the average.","global","5.18"
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,750,042",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"33","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.95"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,103,106,892.06",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,140,971,680.45",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","340,828,234",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.45",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.53",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","159,189,824",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.24",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.59",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","319,418,598.53",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.38",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,054,016",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,955,747,121.12",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.45",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.38",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","42.49",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.38",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.14"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761320 bank conflicts,  which represent 96.75% of the overall 4367616042 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.25"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.55"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.70",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.70",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.8% of the total average of 31.7 cycles between issuing two instructions.","global","13.55"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.7 cycles between issuing two instructions.","global","13.55"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,874.21",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,893",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,149.43",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,988,322",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.37",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.02",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.55"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","19,678,584",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,159,728,640",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","319,418,598.53",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,587,932,528",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,705,991.94",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,568,051,896",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","319,418,598.53",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,587,932,528",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","319,900,098.79",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,351,730,112",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.63% above the average, while the minimum instance value is 0.58% below the average.","global","5.28"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.57% above the average, while the minimum instance value is 0.63% below the average.","global","5.225"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.63% above the average, while the minimum instance value is 0.58% below the average.","global","5.28"
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,813",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"34","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.9"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,128,403,426.62",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,147,665,622.33",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","342,601,597",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.00",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.58",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","159,519,232",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.05",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.74",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","320,077,104.26",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.34",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,595,264",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.94",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.94",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,114,864,344.38",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.00",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.34",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.45",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","45.56",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.34",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.96"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761308 bank conflicts,  which represent 96.75% of the overall 4367616034 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.07"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","14"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.60",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.60",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","14"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","14"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,871.76",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,560",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,186.26",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,993,332",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.32",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","20,512,500",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,186,546,688",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","320,077,104.26",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,648,219,036",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,675,721",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,591,804,640",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","320,077,104.26",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,648,219,036",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","320,397,100.28",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,592,876,144",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.88% above the average, while the minimum instance value is 0.41% below the average.","global","5.494"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.56% above the average, while the minimum instance value is 0.63% below the average.","global","5.196"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.88% above the average, while the minimum instance value is 0.41% below the average.","global","5.494"
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,114",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"35","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.62"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,176,285,347.75",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,160,318,674.23",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","339,171,097",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.87",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.37",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","156,997,824",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.67",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.46",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","317,949,317.50",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.42",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,791,872",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.4"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,576,441,314.24",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.87",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.42",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","76.08",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.42",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.54"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761313 bank conflicts,  which represent 96.75% of the overall 4367616036 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.66"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.13"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.57",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.57",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.0% of the total average of 31.6 cycles between issuing two instructions.","global","13.13"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","13.13"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,874.84",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,978",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,203.27",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,995,645",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.13"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","17,546,672",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,134,636,032",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","317,949,317.50",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,531,638,920",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,421,998.69",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,545,839,664",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","317,949,317.50",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,531,638,920",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","318,044,998.01",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,126,555,680",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.67% below the average.","global","5.306"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.73% above the average, while the minimum instance value is 0.60% below the average.","global","5.375"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.67% below the average.","global","5.306"
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,375",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"36","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.92"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,190,658,646.30",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,164,123,908.97",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","341,461,675",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.29",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.50",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","157,779,616",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.18",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.50",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","319,625,335.56",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.36",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,529,728",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.95",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.95",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,927,862,924.95",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.29",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.36",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","53.09",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.36",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.09"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761310 bank conflicts,  which represent 96.75% of the overall 4367616035 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.19"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.71"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.49",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.49",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.1% of the total average of 31.5 cycles between issuing two instructions.","global","13.71"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.7% of the total average of 31.5 cycles between issuing two instructions.","global","13.71"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,872.33",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,637",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,115.60",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,983,721",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.71"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","19,366,772",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,169,275,904",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","319,625,335.56",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,609,481,010",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,229,917.19",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,576,521,888",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","319,625,335.56",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,609,481,010",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","320,698,563.66",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,437,924,040",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.84% above the average, while the minimum instance value is 0.45% below the average.","global","5.466"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.81% above the average, while the minimum instance value is 0.40% below the average.","global","5.457"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.84% above the average, while the minimum instance value is 0.45% below the average.","global","5.466"
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,329",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"37","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.79"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,225,875,602.10",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,173,488,113.40",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","340,742,080",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.47",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.34",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","156,770,752",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.20",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.40",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","319,564,953.26",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.38",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,595,264",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,532,656,499.60",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.47",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.38",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","67.03",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.38",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.1"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761321 bank conflicts,  which represent 96.75% of the overall 4367616045 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.21"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.53"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.63",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.63",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","13.53"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","13.53"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,872.29",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,631",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,145.24",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,987,753",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.31",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.53"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","17,306,788",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,158,306,816",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","319,564,953.26",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,585,145,032",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,029,210.88",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,566,865,696",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","319,564,953.26",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,585,145,032",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","319,041,236.04",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,340,580,128",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.60% below the average.","global","5.311"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.64% above the average, while the minimum instance value is 0.57% below the average.","global","5.283"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.60% below the average.","global","5.311"
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,509",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"38","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.96"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","7,713,795,498.43",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,038,048,677.29",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","348,196,857",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","84.62",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.91",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","170,840,192",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","90.98",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.89",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","323,841,913.82",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.20",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,485,760",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","64,000",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.12",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.90",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.12",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.90",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.44"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,723,860,015.33",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","84.62",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.20",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","840",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","33.46",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.20",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 26880.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.393"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","84.96"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761321 bank conflicts,  which represent 96.75% of the overall 4367616049 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.03"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.14",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.86",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","15.38"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.89",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.89",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.5% of the total average of 31.9 cycles between issuing two instructions.","global","15.38"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.2% of the total average of 31.9 cycles between issuing two instructions.","global","15.38"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,875.54",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,074",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,272.08",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,372,005,003",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.20",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.94",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","15.38"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","25,219,536",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,271,305,216",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","323,841,913.82",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,838,195,990",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,204,141.56",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,666,785,192",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","323,841,913.82",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,838,195,990",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","321,493,513.54",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","47,352,783,960",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.89% above the average, while the minimum instance value is 0.40% below the average.","global","5.479"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.50% above the average, while the minimum instance value is 0.67% below the average.","global","5.078"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.89% above the average, while the minimum instance value is 0.40% below the average.","global","5.479"
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,144",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"39","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.22"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,311,026,262.41",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,196,001,939.29",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","338,866,413",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.95",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.33",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","154,309,696",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.67",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.43",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","317,949,357",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.43",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,791,872",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.98",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.98",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.4"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,525,241,913.51",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.95",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.43",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","52.89",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.43",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.54"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761319 bank conflicts,  which represent 96.75% of the overall 4367616051 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.66"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.05"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.67",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.67",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.8% of the total average of 31.7 cycles between issuing two instructions.","global","13.05"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.7 cycles between issuing two instructions.","global","13.05"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,877.12",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,288",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,140.06",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,987,048",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.35",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.05"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","16,999,344",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,129,887,744",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","317,949,357",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,521,394,344",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,454,585.56",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,541,720,352",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","317,949,357",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,521,394,344",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","319,961,927.79",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,085,577,376",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.77% above the average, while the minimum instance value is 0.56% below the average.","global","5.411"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.64% above the average, while the minimum instance value is 0.68% below the average.","global","5.322"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.77% above the average, while the minimum instance value is 0.56% below the average.","global","5.411"
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,169",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"40","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,215,250,223.31",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,170,681,694.99",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","341,146,005",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.37",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.50",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","157,159,456",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.37",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.58",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","318,978,536.59",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.37",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,464,192",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","64,000",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,936,626,097.76",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.37",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.37",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","59.38",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.37",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.26"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761305 bank conflicts,  which represent 96.75% of the overall 4367616026 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.37"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.63"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.64",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.64",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","13.63"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.6 cycles between issuing two instructions.","global","13.63"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,871.15",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,476",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,117.43",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,983,970",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.38",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.02",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.63"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","19,333,688",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,164,417,024",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","318,978,536.59",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,598,874,010",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,391,347.19",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,572,276,960",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","318,978,536.59",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,598,874,010",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","318,236,201.36",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,395,496,040",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.91% above the average, while the minimum instance value is 0.48% below the average.","global","5.528"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.79% above the average, while the minimum instance value is 0.44% below the average.","global","5.399"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.91% above the average, while the minimum instance value is 0.48% below the average.","global","5.528"
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,248",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"41","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.69"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,070,318,785.67",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,132,389,305.65",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","343,574,513",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.76",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.46",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","161,120,416",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.48",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.46",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","322,099,673.15",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.31",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,054,016",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.94",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.94",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,762,690,582.92",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.76",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.31",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","83.78",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.31",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.42"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761324 bank conflicts,  which represent 96.75% of the overall 4367616045 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.51"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.01",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.01 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","14.24"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.94",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.94",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.5% of the total average of 31.9 cycles between issuing two instructions.","global","14.24"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.1% of the total average of 31.9 cycles between issuing two instructions.","global","14.24"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,875.07",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,009",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,116.37",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,983,826",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.30",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.24"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","18,945,196",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,201,172,480",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","322,099,673.15",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,681,437,148",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,714,968.94",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,604,825,128",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","322,099,673.15",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,681,437,148",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","318,713,845.39",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,725,748,592",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.57% above the average, while the minimum instance value is 0.59% below the average.","global","5.218"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.58% above the average, while the minimum instance value is 0.64% below the average.","global","5.172"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.57% above the average, while the minimum instance value is 0.59% below the average.","global","5.218"
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,169",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"42","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.92"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,041,770,641.66",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,124,828,351.24",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","343,028,097",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","85.90",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.65",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","161,436,256",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.03",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.63",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","320,170,620.91",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.33",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,464,192",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.94",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.94",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,256,220,015.41",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","85.90",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.33",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","40.63",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.33",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.94"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761319 bank conflicts,  which represent 96.75% of the overall 4367616042 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.04"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","14.1"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.57",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.57",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.0% of the total average of 31.6 cycles between issuing two instructions.","global","14.1"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","14.1"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,870.41",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,376",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,161.17",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,989,919",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.29",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.98",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","14.1"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","21,472,132",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,192,933,376",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","320,170,620.91",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,662,837,424",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,424,503.31",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,597,507,248",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","320,170,620.91",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,662,837,424",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","317,895,509.78",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,651,349,696",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.90% above the average, while the minimum instance value is 0.44% below the average.","global","5.507"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.55% above the average, while the minimum instance value is 0.70% below the average.","global","5.143"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.90% above the average, while the minimum instance value is 0.44% below the average.","global","5.507"
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,607",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"43","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.53"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,230,679,478.91",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,174,719,434.52",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","339,618,320",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.76",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.43",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","156,163,904",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.37",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.44",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","318,987,256.56",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.41",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,316,160",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,758,911,764.91",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.76",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.41",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","81.05",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.41",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.274"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.26"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761338 bank conflicts,  which represent 96.75% of the overall 4367616058 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.37"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.24"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.60",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.61",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","13.24"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","13.24"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,872.27",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,629",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,271.40",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,372,004,911",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.35",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.24"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","18,343,948",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,141,340,160",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","318,987,256.56",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,546,847,010",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","21,240,630.12",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,551,808,776",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","318,987,256.56",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,546,847,010",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","318,173,195.46",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,187,388,040",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.57% above the average, while the minimum instance value is 0.68% below the average.","global","5.231"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.82% above the average, while the minimum instance value is 0.53% below the average.","global","5.452"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.57% above the average, while the minimum instance value is 0.68% below the average.","global","5.231"
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,240",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"44","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.09"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,232,583,945.86",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,175,217,020.17",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","339,360,607",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.83",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.42",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","156,010,080",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.68",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.51",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","317,912,747.32",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.42",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,316,160",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.4"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,753,593,767.79",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.83",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.42",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","102.97",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.42",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.55"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761323 bank conflicts,  which represent 96.75% of the overall 4367616047 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.67"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.17"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.77",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.77",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.7% of the total average of 31.8 cycles between issuing two instructions.","global","13.17"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.4% of the total average of 31.8 cycles between issuing two instructions.","global","13.17"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,876.37",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,186",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,151.29",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,988,576",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.42",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.04",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.17"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","18,299,952",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,137,464,320",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","317,912,747.32",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,538,109,488",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,446,205.44",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,548,366,496",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","317,912,747.32",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,538,109,488",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","319,034,688.72",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,152,437,952",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.79% above the average, while the minimum instance value is 0.58% below the average.","global","5.426"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.64% above the average, while the minimum instance value is 0.57% below the average.","global","5.299"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.79% above the average, while the minimum instance value is 0.58% below the average.","global","5.426"
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,239",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"45","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.86"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,322,989,903.09",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,199,104,919.13",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","338,755,116",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.98",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.36",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","154,039,936",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.65",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.44",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","318,021,720.76",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.43",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,595,264",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.98",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.98",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.4"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,610,893,632.16",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.98",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.43",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","115.87",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.43",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.52"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761332 bank conflicts,  which represent 96.75% of the overall 4367616057 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.64"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.02"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.59",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.59",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","13.02"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","13.02"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,871.16",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,478",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,118.50",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,984,116",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.36",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.02"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","17,381,932",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,128,291,328",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","318,021,720.76",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,517,514,354",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,439,912.88",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,540,246,352",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","318,021,720.76",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,517,514,354",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","319,713,050.74",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,070,057,416",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.60% below the average.","global","5.316"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.55% above the average, while the minimum instance value is 0.66% below the average.","global","5.235"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.60% below the average.","global","5.316"
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,206",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"46","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.05"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,183,567,178.83",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,162,309,940.53",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","342,329,868",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.07",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.55",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","158,315,360",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.77",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.52",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","321,080,240.74",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.34",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,464,192",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.95",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.95",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.42"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,059,973,864.82",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.07",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.34",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","44.40",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.34",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.69"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761309 bank conflicts,  which represent 96.75% of the overall 4367616031 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.79"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.14",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.86",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.93"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.65",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.65",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","13.93"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.6 cycles between issuing two instructions.","global","13.93"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,877.11",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,287",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,141.63",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,987,262",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.26",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.96",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.93"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","20,086,132",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,182,337,536",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","321,080,240.74",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,639,121,098",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,236,295.75",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,588,143,752",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","321,080,240.74",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,639,121,098",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","321,159,391.41",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,556,484,392",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.60% above the average, while the minimum instance value is 0.57% below the average.","global","5.256"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.49% above the average, while the minimum instance value is 0.68% below the average.","global","5.152"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.60% above the average, while the minimum instance value is 0.57% below the average.","global","5.256"
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,016",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"47","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.97"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,159,565,333.28",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,155,894,043.30",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","341,386,976",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.31",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.38",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","158,346,976",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.03",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.46",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","320,162,338",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.37",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,660,800",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,596,695,701.98",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.31",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.37",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.46",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","32",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","51.00",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.37",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 1024.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.205"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.94"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761327 bank conflicts,  which represent 96.75% of the overall 4367616055 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.04"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.69"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.67",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.67",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.8% of the total average of 31.7 cycles between issuing two instructions.","global","13.69"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.7 cycles between issuing two instructions.","global","13.69"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,877.82",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,383",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,102.90",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,981,994",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.28",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.97",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.69"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","17,797,684",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,168,169,984",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","320,162,338",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,606,921,240",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,280,527.31",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,575,524,944",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","320,162,338",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,606,921,240",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","318,478,761.74",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,427,684,960",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.61% above the average, while the minimum instance value is 0.66% below the average.","global","5.259"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.58% above the average, while the minimum instance value is 0.68% below the average.","global","5.202"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.61% above the average, while the minimum instance value is 0.66% below the average.","global","5.259"
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,748,612",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"48","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.96"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,248,872,425.32",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,179,570,402.30",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","340,948,206",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.42",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.31",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","156,427,776",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.15",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.39",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","319,738,041.50",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.38",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,595,264",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,460,008,739.11",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.42",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.38",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","51.42",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.38",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.05"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761321 bank conflicts,  which represent 96.75% of the overall 4367616042 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.16"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.58"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.61",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.61",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.6 cycles between issuing two instructions.","global","13.58"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.6 cycles between issuing two instructions.","global","13.58"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,876.22",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,166",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,050.57",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,974,878",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.36",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.58"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","16,913,796",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,161,411,072",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","319,738,041.50",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,592,148,414",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,461,531.19",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,569,618,408",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","319,738,041.50",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,592,148,414",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","318,107,039.44",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,368,593,656",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.70% above the average, while the minimum instance value is 0.59% below the average.","global","5.347"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.56% above the average, while the minimum instance value is 0.67% below the average.","global","5.184"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.70% above the average, while the minimum instance value is 0.59% below the average.","global","5.347"
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,206",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"49","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.95"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,293,606,272.86",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,191,405,672.01",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","339,649,968",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.75",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.36",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","154,990,912",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.27",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.52",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","319,323,753.71",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.41",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,660,800",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.97",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.97",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,606,442,989.38",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.75",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.41",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","56.48",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.41",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.17"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761322 bank conflicts,  which represent 96.75% of the overall 4367616053 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.28"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.14",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.86",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","13.25"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.73",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.73",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.7% of the total average of 31.7 cycles between issuing two instructions.","global","13.25"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.4% of the total average of 31.7 cycles between issuing two instructions.","global","13.25"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,871.76",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,560",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,126.93",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,985,263",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.40",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.03",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.25"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","17,467,684",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,141,734,400",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","319,323,753.71",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,548,035,510",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,411,421.31",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,552,216,952",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","319,323,753.71",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,548,035,510",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","321,190,733.07",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,192,142,040",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.53% above the average, while the minimum instance value is 0.67% below the average.","global","5.203"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.66% above the average, while the minimum instance value is 0.55% below the average.","global","5.349"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.53% above the average, while the minimum instance value is 0.67% below the average.","global","5.203"
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,748,695",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"50","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.18"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,477,746,821.62",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,240,067,293.25",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","336,510,110",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","87.56",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.52",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","150,222,496",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.84",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.44",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","317,367,024.94",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.49",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","10,420,224",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","64,000",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.00",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.00",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.39"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,121,718,121.37",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","87.56",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.49",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.47",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","136",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","68.13",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.49",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 4352.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.393"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.7"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761314 bank conflicts,  which represent 96.75% of the overall 4367616038 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.83"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.13",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.87",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","12.44"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.47",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.47",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.1% of the total average of 31.5 cycles between issuing two instructions.","global","12.44"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.8% of the total average of 31.5 cycles between issuing two instructions.","global","12.44"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,879.79",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,652",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,251.32",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,372,002,179",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","12.44"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","19,349,212",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,094,193,152",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","317,367,024.94",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,441,292,982",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,950,928.69",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,510,128,200",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","317,367,024.94",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,441,292,982",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","322,215,764.67",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","45,765,171,928",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.39% above the average, while the minimum instance value is 0.84% below the average.","global","5.086"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.81% above the average, while the minimum instance value is 0.48% below the average.","global","5.564"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.39% above the average, while the minimum instance value is 0.84% below the average.","global","5.086"
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,485",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"51","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.46"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,340,767,683.70",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,203,854,924.33",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","337,718,823",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","87.25",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.40",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","153,238,944",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.81",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.48",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","317,475,751.94",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.46",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","20,316,160",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.99",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.99",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.4"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,738,470,241.61",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","87.25",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.46",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.46",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","48.06",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.46",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.67"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761311 bank conflicts,  which represent 96.75% of the overall 4367616034 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.79"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","12.75"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.67",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.67",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.8% of the total average of 31.7 cycles between issuing two instructions.","global","12.75"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.7 cycles between issuing two instructions.","global","12.75"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,875.90",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,951,123",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,212.73",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,996,931",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","12.75"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","17,902,476",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,112,521,728",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","317,475,751.94",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,482,363,678",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","19,151,538.06",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,526,338,696",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","317,475,751.94",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,482,363,678",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","319,954,603.36",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","45,929,454,712",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.56% above the average, while the minimum instance value is 0.73% below the average.","global","5.226"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.95% above the average, while the minimum instance value is 0.41% below the average.","global","5.641"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.56% above the average, while the minimum instance value is 0.73% below the average.","global","5.226"
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,749,493",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"52","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","89.17"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,253,170,649.02",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,180,639,924.00",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","340,447,297",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","86.55",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.31",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","156,119,456",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.30",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.45",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","319,221,377.79",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.39",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,398,656",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","32,000",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","2.96",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","2.96",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.41"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,449,006,945.04",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","86.55",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.39",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","1.46",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","32",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","81.74",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.39",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 1024.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.162"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 339247104 shared load requests.This results in 5272240128 bank conflicts,  which represent 93.38% of the overall 5645828096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.19"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 141854720 shared store requests.This results in 4225761323 bank conflicts,  which represent 96.75% of the overall 4367616046 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.3"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.01",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.01 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","13.45"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.81",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.82",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.8 cycles between issuing two instructions.","global","13.45"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.3% of the total average of 31.8 cycles between issuing two instructions.","global","13.45"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","10,087,872.79",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","1,371,950,700",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","10,088,117.17",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","1,371,983,935",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Grid Size","","512",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Threads","thread","65,536",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","15.06",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.29",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.98",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","13.45"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","16,826,784",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","5,153,922,048",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","319,221,377.79",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","11,574,992,606",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","20,000,716.44",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","4,562,926,872",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","319,221,377.79",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","11,574,992,606",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","318,850,738.87",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","46,299,970,424",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.68% above the average, while the minimum instance value is 0.52% below the average.","global","5.328"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more SMSPs have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.78% above the average, while the minimum instance value is 0.42% below the average.","global","5.417"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","WorkloadDistribution","","","","WorkloadImbalance","OPT","One or more L1 Slices have a much higher number of active cycles than the average number of active cycles. Maximum instance value is 5.68% above the average, while the minimum instance value is 0.52% below the average.","global","5.328"
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","32,748,937",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"53","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(16, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 9498001408 excessive wavefronts (95% of the total 10013444096 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","88.94"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,227,968,913.82",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,174,043,148.93",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,319,149,452",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.34",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.33",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","606,767,360",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.46",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.46",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,274,643,841.76",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.65",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,874,368",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.05",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.05",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.36"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,509,357,497.41",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.34",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.65",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","112",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","73.59",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.65",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 3584.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.185"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.34"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045221 bank conflicts,  which represent 96.76% of the overall 17469935733 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.46"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","10.66"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.58",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.58",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.1% of the total average of 31.6 cycles between issuing two instructions.","global","10.66"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.7% of the total average of 31.6 cycles between issuing two instructions.","global","10.66"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,168.67",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,478,939",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,247,007.36",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,593,001",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.28",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.97",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.66"
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","66,542,612",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,969,851,904",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,274,643,841.76",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,850,733,498",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,943,139.81",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,680,152,552",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,274,643,841.76",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,850,733,498",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,268,478,543.96",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","179,402,933,992",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,140,069",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"54","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.66"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,274,745,530.01",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,186,352,449.04",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,315,496,520",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.59",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.34",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","601,674,080",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.58",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.46",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,272,960,957",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.68",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,005,440",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.06",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.06",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,558,570,952.57",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.59",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.68",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","13.33",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","120",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","83.39",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.68",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 3840.0 bytes sent to the L2 Compression unit only 13.33% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","-14.74"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.46"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045212 bank conflicts,  which represent 96.76% of the overall 17469935729 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.58"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.12",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.88",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 32.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.41"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.74",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.74",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.8% of the total average of 31.7 cycles between issuing two instructions.","global","10.41"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.7 cycles between issuing two instructions.","global","10.41"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,179.59",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,480,424",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,247,078.96",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,602,739",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.35",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.41"
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","66,909,372",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,914,799,616",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,272,960,957",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,726,116,718",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","72,752,896.19",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,631,232,792",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,272,960,957",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,726,116,718",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,290,992,486.78",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,904,466,872",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,137,583",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"55","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.79"
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,247,177,176.85",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,179,122,275.90",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,324,239,377",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.00",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.40",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","607,689,504",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.04",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.52",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,280,481,389.35",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.62",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,070,976",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.04",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.04",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.37"
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,686,765,720.41",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.00",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.62",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","47.60",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.62",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.95"
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045219 bank conflicts,  which represent 96.76% of the overall 17469935727 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.05"
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","11"
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.76",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.77",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.8% of the total average of 31.8 cycles between issuing two instructions.","global","11"
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.5% of the total average of 31.8 cycles between issuing two instructions.","global","11"
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,178.04",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,480,214",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,247,286.39",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,630,949",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.32",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","11"
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","70,012,776",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","20,046,892,032",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,280,481,389.35",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","45,023,836,746",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,447,401.25",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,748,385,192",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,280,481,389.35",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","45,023,836,746",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,274,360,477.99",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","180,095,346,984",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,138,000",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"56","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.72"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,453,237,619.87",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,233,548,540.19",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,308,834,015",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","90.05",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.30",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","585,980,096",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.89",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,268,735,416",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.72",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,808,832",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.08",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.08",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,526,334,546.35",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","90.05",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.72",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","88",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","54.13",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.72",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 2816.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.195"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.75"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045257 bank conflicts,  which represent 96.76% of the overall 17469935777 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.88"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","9.954"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.50",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.50",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.2% of the total average of 31.5 cycles between issuing two instructions.","global","9.954"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.9% of the total average of 31.5 cycles between issuing two instructions.","global","9.954"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,156.04",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,477,222",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,811.66",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,566,386",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.39",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.03",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","9.954"
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","64,573,808",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,813,715,968",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,268,735,416",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,499,772,614",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,301,929.75",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,541,879,712",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,268,735,416",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,499,772,614",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,272,830,467.83",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","177,999,090,456",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,136,601",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"57","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.95"
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,387,236,678.76",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,216,094,121.08",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,320,661,793",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.24",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.32",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","595,930,656",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.18",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.46",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,278,469,450.65",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.64",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,677,760",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.05",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.05",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.36"
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,530,080,734.76",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.24",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.64",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.74",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","27.98",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","41.78",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","1,344",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","81.49",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.64",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960548 bank conflicts,  which represent 93.39% of the overall 22582788132 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.09"
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045251 bank conflicts,  which represent 96.76% of the overall 17469935760 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.19"
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","10.76"
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.94",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.94",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.6% of the total average of 31.9 cycles between issuing two instructions.","global","10.76"
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.3% of the total average of 31.9 cycles between issuing two instructions.","global","10.76"
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,173.26",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,479,564",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,512.94",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,525,760",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.43",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.05",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.76"
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","65,740,104",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,992,845,824",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,278,469,450.65",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,901,783,282",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","76,049,982.94",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,700,427,504",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,278,469,450.65",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,901,783,282",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,279,156,720.38",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","179,607,133,128",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,135,062",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"58","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.83"
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,475,991,707.37",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,239,583,874.86",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,308,269,264",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","90.08",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.33",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","584,152,160",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.92",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.42",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,268,329,420.88",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.73",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,481,152",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.08",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.08",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,608,353,659.09",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","90.08",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.73",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.75",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","74.25",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.73",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.77"
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045209 bank conflicts,  which represent 96.76% of the overall 17469935722 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.91"
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.18",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.82",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","9.915"
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.50",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.50",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.2% of the total average of 31.5 cycles between issuing two instructions.","global","9.915"
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.9% of the total average of 31.5 cycles between issuing two instructions.","global","9.915"
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,145.10",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,475,733",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,764.53",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,559,976",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.45",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.05",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","9.915"
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","65,869,612",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,805,075,456",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,268,329,420.88",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,480,800,640",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","72,795,205.19",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,534,293,416",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,268,329,420.88",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,480,800,640",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,266,672,904.20",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","177,923,202,560",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,135,154",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"59","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.96"
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,432,668,570.34",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,228,155,594.84",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,312,412,074",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.80",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.31",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","589,009,920",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.65",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,272,050,771.65",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.70",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,415,616",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.07",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.07",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,540,761,989.20",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.80",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.70",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","53.60",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.70",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960513 bank conflicts,  which represent 93.39% of the overall 22582788097 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.52"
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045198 bank conflicts,  which represent 96.76% of the overall 17469935705 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.64"
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.2"
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.46",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.46",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.2% of the total average of 31.5 cycles between issuing two instructions.","global","10.2"
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.9% of the total average of 31.5 cycles between issuing two instructions.","global","10.2"
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,146.46",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,475,918",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,734.25",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,555,858",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.2"
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","65,173,248",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,867,701,760",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,272,050,771.65",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,621,810,380",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,163,896.06",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,589,812,864",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,272,050,771.65",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,621,810,380",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,269,690,249.13",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,487,241,520",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,715",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"60","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.94"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,501,787,952.28",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,246,428,626.94",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,304,616,756",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","90.34",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.27",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","580,749,280",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","93.17",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.37",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,264,979,909.35",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.75",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,481,152",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.08",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.08",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.34"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,465,949,836.39",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","90.34",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.75",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","73.32",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.75",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.204"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","87"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045181 bank conflicts,  which represent 96.76% of the overall 17469935682 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","90.14"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.18",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.82",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","9.664"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.52",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.52",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.1% of the total average of 31.5 cycles between issuing two instructions.","global","9.664"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.8% of the total average of 31.5 cycles between issuing two instructions.","global","9.664"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,153.57",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,885",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,704.80",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,551,853",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","9.664"
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","62,901,496",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,749,628,928",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,264,979,909.35",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,356,813,736",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,539,834.81",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,485,313,328",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,264,979,909.35",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,356,813,736",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,265,163,807.35",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","177,427,254,944",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,135,315",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"61","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.97"
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,434,690,915.50",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,228,647,758.89",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,317,706,771",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.44",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.33",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","591,249,568",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.36",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.46",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,276,060,310.41",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.66",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,612,224",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.05",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.05",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.36"
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,601,460,424.24",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.44",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.66",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","100",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","848",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","51.00",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.66",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960518 bank conflicts,  which represent 93.39% of the overall 22582788102 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.25"
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045222 bank conflicts,  which represent 96.76% of the overall 17469935736 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.36"
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.56"
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.67",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.67",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.7 cycles between issuing two instructions.","global","10.56"
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.7 cycles between issuing two instructions.","global","10.56"
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,148.62",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,212",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,666.07",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,546,585",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.32",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.56"
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","66,542,560",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,948,029,440",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,276,060,310.41",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,801,424,436",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","71,962,106.88",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,660,776,192",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,276,060,310.41",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,801,424,436",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,274,721,867.22",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","179,205,697,744",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,412",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"62","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.86"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,438,417,777.32",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,229,630,402.38",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,316,529,713",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.52",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.23",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","590,461,312",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.40",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.38",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,275,536,272.24",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.67",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,743,296",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.06",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.06",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.36"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,325,059,793.25",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.52",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.67",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","66.89",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.67",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.135"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.28"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045221 bank conflicts,  which represent 96.76% of the overall 17469935730 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.4"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","10.48"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.68",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.68",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.7 cycles between issuing two instructions.","global","10.48"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.7 cycles between issuing two instructions.","global","10.48"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,156.25",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,477,250",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,740.10",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,556,654",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.32",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.48"
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","61,353,724",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,930,236,928",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,275,536,272.24",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,761,417,640",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","72,215,233.06",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,645,014,744",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,275,536,272.24",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,761,417,640",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,274,367,733.90",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","179,045,670,560",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,654",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"63","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.9"
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,425,510,951.23",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,226,262,995.68",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,315,647,080",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.58",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.28",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","590,963,648",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.45",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.39",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,274,742,793.53",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.68",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,612,224",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.06",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.06",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,461,665,378.10",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.58",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.68",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.75",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","74.66",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.68",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.34"
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045228 bank conflicts,  which represent 96.76% of the overall 17469935735 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.45"
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.42"
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.68",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.68",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.7 cycles between issuing two instructions.","global","10.42"
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.7 cycles between issuing two instructions.","global","10.42"
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,150.33",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,445",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,697.39",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,550,845",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.42"
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","63,928,700",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,916,682,752",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,274,742,793.53",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,731,793,180",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","70,609,885.81",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,633,168,304",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,274,742,793.53",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,731,793,180",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,277,546,727.12",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,927,172,720",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,133,925",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"64","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.91"
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,472,701,259.09",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,238,736,070.80",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,314,077,645",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.69",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.22",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","586,970,368",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.55",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.37",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,273,393,433.50",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.69",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,677,760",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.06",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.06",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,313,342,373.02",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.69",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.69",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","70.93",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.69",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.43"
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045194 bank conflicts,  which represent 96.76% of the overall 17469935703 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.55"
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","10.31"
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.67",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.67",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.9% of the total average of 31.7 cycles between issuing two instructions.","global","10.31"
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.6% of the total average of 31.7 cycles between issuing two instructions.","global","10.31"
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,149.93",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,391",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,733.01",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,555,689",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.35",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.31"
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","60,776,056",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,892,898,304",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,273,393,433.50",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,678,452,876",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","71,621,049.44",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,612,130,312",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,273,393,433.50",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,678,452,876",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,273,400,017.25",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,713,811,504",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,367",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"65","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.92"
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,443,487,551.00",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,231,014,744.70",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,315,504,951",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.59",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.26",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","589,641,408",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.45",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.37",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,274,847,603.91",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.68",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,612,224",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.06",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.06",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,401,859,972.49",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.59",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.68",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","73.68",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.68",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.33"
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045223 bank conflicts,  which represent 96.76% of the overall 17469935728 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.45"
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.7 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.41"
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.63",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.63",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.0% of the total average of 31.6 cycles between issuing two instructions.","global","10.41"
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.7% of the total average of 31.6 cycles between issuing two instructions.","global","10.41"
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,149.15",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,284",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,705.69",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,551,974",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.35",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.41"
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","62,683,672",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,914,519,552",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,274,847,603.91",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,726,969,866",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","72,120,058.75",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,631,265,568",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,274,847,603.91",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,726,969,866",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,274,100,270.49",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,907,879,464",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,609",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"66","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.92"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,352,011,859.22",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,206,791,370.67",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,324,719,084",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","88.97",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.38",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","600,279,776",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","91.88",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.48",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,282,655,339.15",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.62",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,481,152",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.04",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.04",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.37"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,695,603,697.97",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","88.97",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.62",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","57.38",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.62",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.191"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","85.8"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045198 bank conflicts,  which represent 96.76% of the overall 17469935707 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","88.9"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","11.03"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.63",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.63",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.0% of the total average of 31.6 cycles between issuing two instructions.","global","11.03"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.7% of the total average of 31.6 cycles between issuing two instructions.","global","11.03"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,148.91",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,252",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,836.43",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,569,754",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.33",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","11.03"
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","69,324,880",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","20,054,175,232",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,282,655,339.15",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","45,039,625,580",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,172,660.75",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,754,735,744",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,282,655,339.15",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","45,039,625,580",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,273,347,511.57",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","180,158,502,320",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,132,767",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"67","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.84"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,426,474,757.15",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,226,474,523.25",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,317,466,345",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.46",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.34",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","591,718,848",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.36",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.45",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,275,971,344.41",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.66",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,677,760",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.05",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.05",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.36"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,606,457,639.83",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.46",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.66",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.75",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","24",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","48.60",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.66",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 768.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.173"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.25"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045231 bank conflicts,  which represent 96.76% of the overall 17469935737 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.37"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.16",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.84",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.54"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.59",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.59",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.0% of the total average of 31.6 cycles between issuing two instructions.","global","10.54"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.7% of the total average of 31.6 cycles between issuing two instructions.","global","10.54"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,147.87",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,110",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,853.60",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,572,090",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.54"
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","66,687,780",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,944,415,744",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,275,971,344.41",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,793,258,546",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","70,977,933.56",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,657,568,648",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,275,971,344.41",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,793,258,546",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,272,468,646.50",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","179,173,034,184",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,923",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"68","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.87"
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,426,706,471.83",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,226,543,580.85",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,308,255,738",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","90.09",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.30",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","587,565,984",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.95",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.40",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,267,994,733.91",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.73",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","19,333,120",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.08",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.08",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,506,088,984.21",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","90.09",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.73",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","69.62",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.73",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.8"
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045200 bank conflicts,  which represent 96.76% of the overall 17469935722 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.93"
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.14",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.86",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","9.914"
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.55",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.55",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.1% of the total average of 31.6 cycles between issuing two instructions.","global","9.914"
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.8% of the total average of 31.6 cycles between issuing two instructions.","global","9.914"
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,148.38",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,180",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,712.26",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,552,868",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.35",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","9.914"
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","64,376,832",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,804,984,320",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,267,994,733.91",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,480,247,658",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","72,148,029.12",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,534,151,952",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,267,994,733.91",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,480,247,658",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,282,915,911.20",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","177,920,990,632",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,606",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"69","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.94"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,431,085,034.59",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,227,738,372.44",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,312,916,178",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.77",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.36",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","589,346,592",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.62",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.48",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,272,476,605.03",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.69",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,546,688",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.07",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.07",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,678,017,596.82",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.77",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.69",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","72",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","55.82",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.69",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 2304.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.202"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.49"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045235 bank conflicts,  which represent 96.76% of the overall 17469935743 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.61"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.18",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.82",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.23"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.48",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.48",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.2% of the total average of 31.5 cycles between issuing two instructions.","global","10.23"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.9% of the total average of 31.5 cycles between issuing two instructions.","global","10.23"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,150.76",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,503",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,758.70",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,559,183",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.42",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.04",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.23"
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","67,738,348",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,875,324,928",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,272,476,605.03",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,638,955,708",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","74,156,384.19",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,596,566,712",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,272,476,605.03",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,638,955,708",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,267,183,833.85",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,555,822,832",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,136,144",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"70","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.93"
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,440,302,354.10",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,230,142,795.75",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,308,513,816",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","90.07",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.31",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","586,734,560",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","93.04",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.40",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,266,699,226.38",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.72",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,546,688",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.08",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.08",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,535,761,943.19",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","90.07",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.72",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.75",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","58.35",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.72",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.89"
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045197 bank conflicts,  which represent 96.76% of the overall 17469935706 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","90.02"
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.18",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.82",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","9.932"
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.49",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.49",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.2% of the total average of 31.5 cycles between issuing two instructions.","global","9.932"
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.9% of the total average of 31.5 cycles between issuing two instructions.","global","9.932"
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,163.97",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,478,300",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,715.90",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,553,363",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.36",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","9.932"
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","64,829,804",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,808,868,352",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,266,699,226.38",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,489,095,596",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,170,839.19",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,537,592,904",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,266,699,226.38",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,489,095,596",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,266,406,280.82",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","177,956,382,384",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,135,475",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"71","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.82"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,476,173,990.42",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,239,623,571.71",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,309,575,315",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.99",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.30",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","584,723,680",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.87",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,269,033,963.53",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.72",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,677,760",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.07",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.07",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,528,960,468.99",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.99",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.72",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.75",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","64.11",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.72",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.19"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.73"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045205 bank conflicts,  which represent 96.76% of the overall 17469935710 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.86"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.18",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.82",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.01"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.44",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.44",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.3% of the total average of 31.4 cycles between issuing two instructions.","global","10.01"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.9% of the total average of 31.4 cycles between issuing two instructions.","global","10.01"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,150.59",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,480",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,689.64",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,549,791",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.31",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.01"
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","64,483,336",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,824,878,592",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,269,033,963.53",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,525,116,094",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","72,774,615.75",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,551,779,232",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,269,033,963.53",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,525,116,094",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,265,217,624.68",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,100,464,376",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,112",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"72","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.92"
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,475,343,608.63",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,239,435,870.89",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,306,635,120",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","90.20",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.27",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","583,463,808",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","93.00",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.37",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,267,287,991.56",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.74",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,546,688",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.08",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.08",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.34"
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,445,105,434.89",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","90.20",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.74",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","83.33",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","48",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","54.09",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.74",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.85"
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045194 bank conflicts,  which represent 96.76% of the overall 17469935712 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.98"
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","9.803"
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.49",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.49",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.2% of the total average of 31.5 cycles between issuing two instructions.","global","9.803"
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.9% of the total average of 31.5 cycles between issuing two instructions.","global","9.803"
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,153.61",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,891",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,743.21",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,557,076",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.35",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","9.803"
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","62,815,448",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,780,225,024",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,267,287,991.56",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,425,424,912",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","71,648,056.88",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,512,376,808",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,267,287,991.56",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,425,424,912",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,268,352,580.76",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","177,701,699,648",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,133,676",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"73","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","92"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,273,714,729.14",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,186,057,644.22",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,315,538,141",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.59",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.58",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","601,773,856",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.70",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.49",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,271,335,628.68",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.68",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,612,224",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.06",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.06",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","4,171,370,050.35",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.59",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.68",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","57.52",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.68",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.476"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.57"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045209 bank conflicts,  which represent 96.76% of the overall 17469935721 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.69"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.13",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.87",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","10.41"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","32.08",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.08",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 43.4% of the total average of 32.1 cycles between issuing two instructions.","global","10.41"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.1% of the total average of 32.1 cycles between issuing two instructions.","global","10.41"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,165.46",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,478,502",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,247,162.54",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,614,106",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.32",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.41"
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","78,444,420",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,915,620,864",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,271,335,628.68",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,727,496,332",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","82,517,926.88",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,631,845,992",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,271,335,628.68",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,727,496,332",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,285,638,913.54",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,909,985,328",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,135,447",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"74","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.67"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,399,475,825.04",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,219,382,140.82",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,316,531,957",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.52",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.32",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","593,194,304",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.40",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.48",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,275,491,326.44",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.67",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,481,152",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.06",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.06",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.36"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,557,155,882.60",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.52",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.67",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","8",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","50.43",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.67",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 256.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.154"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.29"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045196 bank conflicts,  which represent 96.76% of the overall 17469935707 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.4"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.15",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.85",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","0.99",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 0.99 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.48"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.61",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.61",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.0% of the total average of 31.6 cycles between issuing two instructions.","global","10.48"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.7% of the total average of 31.6 cycles between issuing two instructions.","global","10.48"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,157.33",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,477,397",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,617.04",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,539,917",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.29",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","3.98",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.48"
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","65,940,144",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,930,084,864",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,275,491,326.44",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,761,863,206",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","72,892,015.94",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,645,028,896",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,275,491,326.44",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,761,863,206",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,279,248,473.23",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","179,047,452,824",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,135,161",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"75","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.9"
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,408,594,513.61",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,221,755,618.47",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,309,956,194",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.97",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.31",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","589,597,344",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.86",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.45",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,269,110,116.32",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.71",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,481,152",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.07",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.07",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,532,663,512.13",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.97",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.71",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","0",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","61.49",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.71",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.72"
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045201 bank conflicts,  which represent 96.76% of the overall 17469935734 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.85"
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","10.03"
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.53",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.54",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.1% of the total average of 31.5 cycles between issuing two instructions.","global","10.03"
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.8% of the total average of 31.5 cycles between issuing two instructions.","global","10.03"
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,153.31",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,850",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,684.40",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,549,078",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.01",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.03"
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","65,089,032",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,830,739,968",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,269,110,116.32",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,538,049,760",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,180,745",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,556,953,680",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,269,110,116.32",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,538,049,760",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,270,871,737.24",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,152,199,040",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,135,081",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"76","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.9"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,396,098,891.53",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,218,443,563.73",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,307,988,359",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","90.10",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.31",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","589,590,784",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","93.10",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.41",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,265,886,843.09",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.73",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,546,688",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.08",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.08",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.34"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,528,985,419.15",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","90.10",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.73",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","16",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","59.04",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.73",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 512.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.22"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.94"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045196 bank conflicts,  which represent 96.76% of the overall 17469935704 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","90.08"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.17",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.83",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, which already limits the scheduler to less than a warp per instruction.","local","9.896"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.46",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.46",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.2% of the total average of 31.5 cycles between issuing two instructions.","global","9.896"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.9% of the total average of 31.5 cycles between issuing two instructions.","global","9.896"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,160.68",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,477,852",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,722.21",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,554,220",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","9.896"
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","65,020,540",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,801,050,112",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,265,886,843.09",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,471,154,164",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,535,250.38",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,530,618,328",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,265,886,843.09",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,471,154,164",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,271,358,457.15",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","177,884,616,656",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,134,692",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"77","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.8"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Frequency","hz","8,405,213,231.44",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Frequency","hz","2,220,887,338.18",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","1,309,915,675",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Memory Throughput","%","89.97",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","DRAM Throughput","%","1.32",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Duration","ns","589,812,448",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","92.91",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.43",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1,268,482,856.76",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.71",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight","","","","SOLBottleneck","INF","This workload is utilizing greater than 80.0% of the available compute or memory performance of the device. To further improve performance, work will likely need to be shifted from the most utilized to another unit. Start by analyzing L1 in the Memory Workload Analysis section.","",""
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved  close to 1% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Buffer Size","byte","18,481,152",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","Maximum Sampling Interval","ns","128,000",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","PM Sampling","# Pass Groups","","2",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.13",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.12",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issue Slots Busy","%","3.07",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.13",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Compute Workload Analysis","SM Busy","%","3.07",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this workload is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","98.35"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Requests","","0",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Local Memory Spilling Request Overhead","%","0",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Memory Throughput","byte/s","3,562,471,031.47",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Busy","%","89.97",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Max Bandwidth","%","8.71",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L1/TEX Hit Rate","%","0.76",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Persisting Size","byte","6,291,456",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Ratio","","0",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Compression Input Sectors","sector","16",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","L2 Hit Rate","%","57.53",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Memory Workload Analysis","Mem Pipes Busy","%","8.71",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","OPT","Out of the 512.0 bytes sent to the L2 Compression unit only 0.00% were successfully compressed. To increase this success rate, consider marking only those memory regions as compressible that contain the most zero values and/or expose the most homogeneous values.","global","1.2"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared loads might not be optimal and causes on average a 16.6 - way bank conflict across all 1356464128 shared load requests.This results in 21088960512 bank conflicts,  which represent 93.39% of the overall 22582788096 wavefronts for shared loads. Check the Source Counters section for uncoalesced shared loads.","global","86.76"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","MemoryWorkloadAnalysis_Tables","","","","SharedMemoryConflicts","OPT","The memory access pattern for shared stores might not be optimal and causes on average a 30.8 - way bank conflict across all 566890496 shared store requests.This results in 16903045204 bank conflicts,  which represent 96.76% of the overall 17469935710 wavefronts for shared stores. Check the Source Counters section for uncoalesced shared stores.","global","89.89"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","One or More Eligible","%","3.18",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Issued Warp Per Scheduler","","0.03",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","No Eligible","%","96.82",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Active Warps Per Scheduler","warp","1.00",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.03",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 31.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 1.00 active warps per scheduler, but only an average of 0.03 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","10.03"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.58",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.58",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Active Threads Per Warp","","32.00",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.74",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.9 cycles being stalled waiting for a scoreboard dependency on a MIO (memory input/output) operation (not to L1TEX). The primary reason for a high number of stalls due to short scoreboards is typically memory operations to shared memory. Other reasons include frequent execution of special math instructions (e.g. MUFU) or dynamic branching (e.g. BRX, JMX). Consult the Memory Workload Analysis section to verify if there are shared memory operations and reduce bank conflicts, if reported. Assigning frequently accessed values to variables can assist the compiler in using low-latency registers instead of direct memory accesses. This stall type represents about 44.1% of the total average of 31.6 cycles between issuing two instructions.","global","10.03"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this workload spends 13.5 cycles being stalled waiting for sibling warps at a CTA barrier. A high number of warps waiting at a barrier is commonly caused by diverging code paths before a barrier. This causes some warps to wait a long time until other warps reach the synchronization point. Whenever possible, try to divide up the work into blocks of uniform workloads. If the block size is 512 threads or greater, consider splitting it into smaller groups. This can increase eligible warps without affecting occupancy, unless shared memory becomes a new occupancy limiter. Also, try to identify which barrier instruction causes the most stalls, and optimize the code executed before that synchronization point first. This stall type represents about 42.7% of the total average of 31.6 cycles between issuing two instructions.","global","10.03"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","40,246,148.33",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Executed Instructions","inst","5,473,476,173",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","40,246,811.54",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Instruction Statistics","Issued Instructions","inst","5,473,566,369",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Block Size","","128",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Grid Size","","1,024",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Registers Per Thread","register/thread","40",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Shared Memory Configuration Size","byte","102,400",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Driver Shared Memory Per Block","byte/block","1,024",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","98,816",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# SMs","SM","34",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Stack Size","","1,024",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Threads","thread","131,072",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","# TPCs","","17",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Enabled TPC IDs","","all",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Uses Green Context","","0",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Launch Statistics","Waves Per SM","","30.12",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit SM","block","24",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Registers","block","12",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Shared Mem","block","1",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Block Limit Warps","block","12",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Active Warps per SM","warp","4",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Theoretical Occupancy","%","8.33",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Occupancy","%","8.34",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","Achieved Active Warps Per SM","warp","4.00",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Occupancy","","","","TheoreticalOccupancy","OPT","The 1.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (8.3%) is limited by the required amount of shared memory.","global","10.03"
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average DRAM Active Cycles","cycle","65,662,180",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total DRAM Elapsed Cycles","cycle","19,829,997,568",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","1,268,482,856.76",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","44,536,857,910",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","73,532,598.50",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","17,556,376,352",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","1,268,482,856.76",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","44,536,857,910",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","1,267,476,392.30",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","178,147,431,640",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions Ratio","%","0.02",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Instructions","inst","129,135,445",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Branch Efficiency","%","100",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","Source Counters","Avg. Divergent Branches","branches","0",
"78","26448","python.exe","127.0.0.1","flash_attn_fwd_kernel(const __half *, const __half *, const __half *, __half *, int, float)","1","7","(128, 1, 1)","(32, 32, 1)","0","8.9","SourceCounters","","","","UncoalescedSharedAccess","OPT","This kernel has uncoalesced shared accesses resulting in a total of 37992005632 excessive wavefronts (95% of the total 40052723712 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations. The CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#shared-memory-in-matrix-multiplication-c-ab) has an example on optimizing shared memory accesses.","global","91.86"
